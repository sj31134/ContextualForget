#!/usr/bin/env python3
"""
ContextualForget ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ContextualForgetì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.
"""

import json
from pathlib import Path
from datetime import datetime, timedelta

# ContextualForget ëª¨ë“ˆ import
from contextualforget.core import ForgettingManager, create_default_forgetting_policy
from contextualforget.query import AdvancedQueryEngine
from contextualforget.llm import NaturalLanguageProcessor
from contextualforget.visualization import GraphVisualizer
from contextualforget.performance import GraphOptimizer, MemoryOptimizer


def example_1_basic_query():
    """ì˜ˆì œ 1: ê¸°ë³¸ ì¿¼ë¦¬ ì‚¬ìš©ë²•"""
    print("=== ì˜ˆì œ 1: ê¸°ë³¸ ì¿¼ë¦¬ ===")
    
    # ê·¸ë˜í”„ ë¡œë“œ
    graph_path = "data/processed/graph.gpickle"
    if not Path(graph_path).exists():
        print("âŒ ê·¸ë˜í”„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:")
        print("   python scripts/generate_sample_data.py")
        print("   python scripts/process_all_data.py")
        return
    
    # ê³ ê¸‰ ì¿¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™”
    query_engine = AdvancedQueryEngine(graph_path)
    
    # GUIDë¡œ ê²€ìƒ‰
    print("\n1. GUID ê²€ìƒ‰:")
    result = query_engine.query_by_guid("1kTvXnbbzCWw8lcMd1dR4o")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰
    print("\n2. í‚¤ì›Œë“œ ê²€ìƒ‰:")
    result = query_engine.search_by_keywords(["ë²½ì²´", "ë‘ê»˜"], ttl=30)
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    # ì‹œê°„ ë²”ìœ„ ê²€ìƒ‰
    print("\n3. ì‹œê°„ ë²”ìœ„ ê²€ìƒ‰:")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=7)
    result = query_engine.query_by_date_range(
        start_date=start_date,
        end_date=end_date
    )
    print(json.dumps(result, indent=2, ensure_ascii=False))


def example_2_forgetting_mechanisms():
    """ì˜ˆì œ 2: ë§ê° ë©”ì»¤ë‹ˆì¦˜ ì‚¬ìš©ë²•"""
    print("\n=== ì˜ˆì œ 2: ë§ê° ë©”ì»¤ë‹ˆì¦˜ ===")
    
    # ë§ê° ë§¤ë‹ˆì € ì´ˆê¸°í™”
    forgetting_manager = ForgettingManager()
    
    # ê¸°ë³¸ ë§ê° ì •ì±… ìƒì„±
    policy = create_default_forgetting_policy()
    
    # ê·¸ë˜í”„ ë¡œë“œ
    graph_path = "data/processed/graph.gpickle"
    if not Path(graph_path).exists():
        print("âŒ ê·¸ë˜í”„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    import pickle
    with open(graph_path, 'rb') as f:
        graph = pickle.load(f)
    
    print(f"ì›ë³¸ ê·¸ë˜í”„: {graph.number_of_nodes()}ê°œ ë…¸ë“œ, {graph.number_of_edges()}ê°œ ì—£ì§€")
    
    # ë§ê° ì •ì±… ì ìš©
    current_time = datetime.now()
    updated_graph = forgetting_manager.apply_forgetting(graph, current_time)
    
    print(f"ë§ê° ì ìš© í›„: {updated_graph.number_of_nodes()}ê°œ ë…¸ë“œ, {updated_graph.number_of_edges()}ê°œ ì—£ì§€")
    
    # ë§ê° í†µê³„
    stats = forgetting_manager.get_forgetting_stats()
    print(f"ë§ê° í†µê³„: {stats}")


def example_3_natural_language_processing():
    """ì˜ˆì œ 3: ìì—°ì–´ ì²˜ë¦¬ ì‚¬ìš©ë²•"""
    print("\n=== ì˜ˆì œ 3: ìì—°ì–´ ì²˜ë¦¬ ===")
    
    # ìì—°ì–´ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    nlp = NaturalLanguageProcessor()
    
    # ë‹¤ì–‘í•œ ì§ˆë¬¸ ì˜ˆì œ
    questions = [
        "ê·¸ë˜í”„ì— ëª‡ ê°œì˜ ë…¸ë“œê°€ ìˆì–´?",
        "GUID 1kTvXnbbzCWw8lcMd1dR4oì™€ ê´€ë ¨ëœ ì´ìŠˆëŠ”?",
        "ìµœê·¼ 7ì¼ ì´ë‚´ì— ìƒì„±ëœ BCF ì´ìŠˆë¥¼ ë³´ì—¬ì¤˜",
        "ë²½ì²´ì™€ ê´€ë ¨ëœ ëª¨ë“  ì´ìŠˆë¥¼ ì°¾ì•„ì¤˜"
    ]
    
    for question in questions:
        print(f"\nì§ˆë¬¸: {question}")
        try:
            result = nlp.process_query(question)
            print(f"ë‹µë³€: {json.dumps(result, indent=2, ensure_ascii=False)}")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")


def example_4_visualization():
    """ì˜ˆì œ 4: ì‹œê°í™” ì‚¬ìš©ë²•"""
    print("\n=== ì˜ˆì œ 4: ì‹œê°í™” ===")
    
    graph_path = "data/processed/graph.gpickle"
    if not Path(graph_path).exists():
        print("âŒ ê·¸ë˜í”„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    import pickle
    with open(graph_path, 'rb') as f:
        graph = pickle.load(f)
    
    # ê·¸ë˜í”„ ì‹œê°í™”
    visualizer = GraphVisualizer(graph)
    
    # ì „ì²´ ê·¸ë˜í”„ ì‹œê°í™”
    print("ì „ì²´ ê·¸ë˜í”„ ì‹œê°í™” ì¤‘...")
    visualizer.visualize_full_graph(
        output_path="examples/full_graph.png",
        max_nodes=50  # ë„ˆë¬´ ë§ì€ ë…¸ë“œê°€ ìˆìœ¼ë©´ ì¼ë¶€ë§Œ í‘œì‹œ
    )
    print("âœ… ì „ì²´ ê·¸ë˜í”„ ì €ì¥: examples/full_graph.png")
    
    # íŠ¹ì • GUID ì£¼ë³€ ì„œë¸Œê·¸ë˜í”„ ì‹œê°í™”
    print("ì„œë¸Œê·¸ë˜í”„ ì‹œê°í™” ì¤‘...")
    try:
        visualizer.visualize_subgraph(
            target_guid="1kTvXnbbzCWw8lcMd1dR4o",
            output_path="examples/subgraph.png",
            max_depth=2
        )
        print("âœ… ì„œë¸Œê·¸ë˜í”„ ì €ì¥: examples/subgraph.png")
    except ValueError as e:
        print(f"âš ï¸ ì„œë¸Œê·¸ë˜í”„ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    # íƒ€ì„ë¼ì¸ ì‹œê°í™”
    print("íƒ€ì„ë¼ì¸ ì‹œê°í™” ì¤‘...")
    visualizer.visualize_timeline(
        output_path="examples/timeline.png",
        days=30
    )
    print("âœ… íƒ€ì„ë¼ì¸ ì €ì¥: examples/timeline.png")


def example_5_performance_optimization():
    """ì˜ˆì œ 5: ì„±ëŠ¥ ìµœì í™” ì‚¬ìš©ë²•"""
    print("\n=== ì˜ˆì œ 5: ì„±ëŠ¥ ìµœì í™” ===")
    
    graph_path = "data/processed/graph.gpickle"
    if not Path(graph_path).exists():
        print("âŒ ê·¸ë˜í”„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê·¸ë˜í”„ ìµœì í™”
    optimizer = GraphOptimizer()
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    print("ë©”ëª¨ë¦¬ ìµœì í™” ì¤‘...")
    memory_optimizer = MemoryOptimizer()
    
    import pickle
    with open(graph_path, 'rb') as f:
        graph = pickle.load(f)
    
    # ì••ì¶•ëœ ê·¸ë˜í”„ ìƒì„±
    compressed_graph = memory_optimizer.compress_graph(graph)
    
    print(f"ì›ë³¸ ê·¸ë˜í”„ í¬ê¸°: {graph.number_of_nodes()}ê°œ ë…¸ë“œ")
    print(f"ì••ì¶•ëœ ê·¸ë˜í”„ í¬ê¸°: {compressed_graph.number_of_nodes()}ê°œ ë…¸ë“œ")
    
    # ì••ì¶•ëœ ê·¸ë˜í”„ ì €ì¥
    compressed_path = "examples/compressed_graph.gpickle"
    memory_optimizer.save_graph_compressed(compressed_graph, compressed_path)
    print(f"âœ… ì••ì¶•ëœ ê·¸ë˜í”„ ì €ì¥: {compressed_path}")


def example_6_batch_operations():
    """ì˜ˆì œ 6: ë°°ì¹˜ ì‘ì—… ì‚¬ìš©ë²•"""
    print("\n=== ì˜ˆì œ 6: ë°°ì¹˜ ì‘ì—… ===")
    
    graph_path = "data/processed/graph.gpickle"
    if not Path(graph_path).exists():
        print("âŒ ê·¸ë˜í”„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°°ì¹˜ ì¿¼ë¦¬
    query_engine = AdvancedQueryEngine(graph_path)
    
    # ì—¬ëŸ¬ GUIDë¥¼ í•œ ë²ˆì— ê²€ìƒ‰
    guids = [
        "1kTvXnbbzCWw8lcMd1dR4o",
        "2mUwYoaa3DXx9mdNe2eR5p",
        "3nVxZpbb4EYy0neOf3fS6q"
    ]
    
    print("ë°°ì¹˜ GUID ê²€ìƒ‰:")
    for guid in guids:
        try:
            result = query_engine.query_by_guid(guid)
            print(f"GUID {guid}: {len(result.get('related_issues', []))}ê°œ ê´€ë ¨ ì´ìŠˆ")
        except Exception as e:
            print(f"GUID {guid}: ê²€ìƒ‰ ì‹¤íŒ¨ - {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ContextualForget ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ")
    print("=" * 50)
    
    # ì˜ˆì œ ë””ë ‰í† ë¦¬ ìƒì„±
    Path("examples").mkdir(exist_ok=True)
    
    # ê° ì˜ˆì œ ì‹¤í–‰
    try:
        example_1_basic_query()
        example_2_forgetting_mechanisms()
        example_3_natural_language_processing()
        example_4_visualization()
        example_5_performance_optimization()
        example_6_batch_operations()
        
        print("\nâœ… ëª¨ë“  ì˜ˆì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nìƒì„±ëœ íŒŒì¼ë“¤:")
        print("- examples/full_graph.png")
        print("- examples/subgraph.png")
        print("- examples/timeline.png")
        print("- examples/compressed_graph.gpickle")
        
    except Exception as e:
        print(f"\nâŒ ì˜ˆì œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
