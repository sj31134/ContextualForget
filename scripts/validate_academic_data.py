#!/usr/bin/env python3
"""
í•™ìˆ  ë°ì´í„°ì…‹ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025-10-15
ìš©ë„: ë‹¤ìš´ë¡œë“œëœ í•™ìˆ  ë°ì´í„°ì…‹ì˜ ë¬´ê²°ì„± ë° í˜•ì‹ ê²€ì¦
"""

import json
import zipfile
import os
from pathlib import Path
from typing import Dict, List, Tuple
import sys

PROJECT_ROOT = Path(__file__).parent.parent
ACADEMIC_DIR = PROJECT_ROOT / "data" / "external" / "academic"

class AcademicDataValidator:
    """í•™ìˆ  ë°ì´í„°ì…‹ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.slabim_dir = ACADEMIC_DIR / "slabim"
        self.duraark_dir = ACADEMIC_DIR / "duraark"
        self.schependomlaan_dir = ACADEMIC_DIR / "schependomlaan"
        self.results = {
            "slabim": {},
            "duraark": {},
            "schependomlaan": {},
            "summary": {},
            "errors": [],
            "warnings": []
        }
    
    def validate_slabim_data(self) -> Dict:
        """SLABIM ë°ì´í„° ê²€ì¦"""
        print("ğŸ” SLABIM ë°ì´í„° ê²€ì¦ ì¤‘...")
        
        if not self.slabim_dir.exists():
            self.results["errors"].append(
                f"SLABIM ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {self.slabim_dir}"
            )
            return {"status": "not_found", "count": 0}
        
        # SLAM ìŠ¤ìº” ë°ì´í„° í™•ì¸
        slam_files = list(self.slabim_dir.rglob("*.ply")) + list(self.slabim_dir.rglob("*.pcd"))
        print(f"  âœ… SLAM ìŠ¤ìº” íŒŒì¼: {len(slam_files)}ê°œ")
        
        # BIM ëª¨ë¸ í™•ì¸
        bim_files = list(self.slabim_dir.rglob("*.ifc")) + list(self.slabim_dir.rglob("*.fbx"))
        print(f"  âœ… BIM ëª¨ë¸ íŒŒì¼: {len(bim_files)}ê°œ")
        
        # ì‹œê°„ì  ë°ì´í„° í™•ì¸
        temporal_files = list(self.slabim_dir.rglob("*.json")) + list(self.slabim_dir.rglob("*.csv"))
        print(f"  âœ… ì‹œê°„ì  ë°ì´í„°: {len(temporal_files)}ê°œ")
        
        # ì´ í¬ê¸°
        total_size = sum(f.stat().st_size for f in self.slabim_dir.rglob("*") if f.is_file())
        total_size_mb = total_size / (1024 * 1024)
        print(f"  âœ… ì´ í¬ê¸°: {total_size_mb:.2f} MB")
        
        result = {
            "status": "ok" if len(slam_files) > 0 or len(bim_files) > 0 else "warning",
            "slam_count": len(slam_files),
            "bim_count": len(bim_files),
            "temporal_count": len(temporal_files),
            "total_size_mb": total_size_mb
        }
        
        self.results["slabim"] = result
        return result
    
    def validate_duraark_data(self) -> Dict:
        """DURAARK ë°ì´í„° ê²€ì¦"""
        print("\nğŸ” DURAARK ë°ì´í„° ê²€ì¦ ì¤‘...")
        
        if not self.duraark_dir.exists():
            self.results["errors"].append(
                f"DURAARK ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {self.duraark_dir}"
            )
            return {"status": "not_found", "count": 0}
        
        # IFC íŒŒì¼ í™•ì¸
        ifc_files = list(self.duraark_dir.rglob("*.ifc"))
        print(f"  âœ… IFC íŒŒì¼: {len(ifc_files)}ê°œ")
        
        # ë¶„ì•¼ë³„ ë¶„ë¥˜ í™•ì¸
        disciplines = {}
        for ifc_file in ifc_files:
            # íŒŒì¼ëª…ì—ì„œ ë¶„ì•¼ ì¶”ì¶œ (ì˜ˆ: structural, architectural, mep)
            filename = ifc_file.name.lower()
            if "structural" in filename or "structure" in filename:
                disciplines["structural"] = disciplines.get("structural", 0) + 1
            elif "architectural" in filename or "arch" in filename:
                disciplines["architectural"] = disciplines.get("architectural", 0) + 1
            elif "mep" in filename or "mechanical" in filename or "electrical" in filename:
                disciplines["mep"] = disciplines.get("mep", 0) + 1
            else:
                disciplines["other"] = disciplines.get("other", 0) + 1
        
        print(f"  âœ… ë¶„ì•¼ë³„ ë¶„í¬: {disciplines}")
        
        # í”„ë¡œì íŠ¸ ë¬¸ì„œ í™•ì¸
        doc_files = list(self.duraark_dir.rglob("*.pdf")) + list(self.duraark_dir.rglob("*.doc"))
        print(f"  âœ… í”„ë¡œì íŠ¸ ë¬¸ì„œ: {len(doc_files)}ê°œ")
        
        # ì´ í¬ê¸°
        total_size = sum(f.stat().st_size for f in self.duraark_dir.rglob("*") if f.is_file())
        total_size_mb = total_size / (1024 * 1024)
        print(f"  âœ… ì´ í¬ê¸°: {total_size_mb:.2f} MB")
        
        result = {
            "status": "ok" if len(ifc_files) > 0 else "warning",
            "ifc_count": len(ifc_files),
            "disciplines": disciplines,
            "doc_count": len(doc_files),
            "total_size_mb": total_size_mb
        }
        
        self.results["duraark"] = result
        return result
    
    def validate_schependomlaan_data(self) -> Dict:
        """Schependomlaan ë°ì´í„° ê²€ì¦"""
        print("\nğŸ” Schependomlaan ë°ì´í„° ê²€ì¦ ì¤‘...")
        
        if not self.schependomlaan_dir.exists():
            self.results["errors"].append(
                f"Schependomlaan ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {self.schependomlaan_dir}"
            )
            return {"status": "not_found", "count": 0}
        
        # BCF íŒŒì¼ í™•ì¸ (ê°€ì¥ ì¤‘ìš”)
        bcf_files = list(self.schependomlaan_dir.rglob("*.bcf")) + list(self.schependomlaan_dir.rglob("*.bcfzip"))
        print(f"  âœ… BCF íŒŒì¼: {len(bcf_files)}ê°œ")
        
        # ì£¼ì°¨ë³„ BIM ëª¨ë¸ í™•ì¸
        weekly_models = list(self.schependomlaan_dir.rglob("*week*.ifc")) + list(self.schependomlaan_dir.rglob("*week*.fbx"))
        print(f"  âœ… ì£¼ì°¨ë³„ ëª¨ë¸: {len(weekly_models)}ê°œ")
        
        # ì´ë²¤íŠ¸ ë¡œê·¸ í™•ì¸
        event_files = list(self.schependomlaan_dir.rglob("*event*.csv")) + list(self.schependomlaan_dir.rglob("*log*.json"))
        print(f"  âœ… ì´ë²¤íŠ¸ ë¡œê·¸: {len(event_files)}ê°œ")
        
        # BCF ë‚´ìš© ê²€ì¦ (ìƒ˜í”Œ)
        bcf_validation = {"valid_bcf": 0, "invalid_bcf": 0}
        for bcf_file in bcf_files[:5]:  # ìƒ˜í”Œ 5ê°œë§Œ ê²€ì¦
            try:
                if bcf_file.suffix == ".bcfzip":
                    with zipfile.ZipFile(bcf_file, 'r') as zip_ref:
                        # BCF êµ¬ì¡° í™•ì¸
                        file_list = zip_ref.namelist()
                        if any("markup.bcf" in f for f in file_list):
                            bcf_validation["valid_bcf"] += 1
                        else:
                            bcf_validation["invalid_bcf"] += 1
                else:
                    # .bcf íŒŒì¼ ì§ì ‘ ê²€ì¦
                    with open(bcf_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if "markup" in content and "topic" in content:
                            bcf_validation["valid_bcf"] += 1
                        else:
                            bcf_validation["invalid_bcf"] += 1
            except Exception as e:
                bcf_validation["invalid_bcf"] += 1
                self.results["warnings"].append(
                    f"BCF íŒŒì¼ ê²€ì¦ ì˜¤ë¥˜: {bcf_file.name} - {str(e)}"
                )
        
        if bcf_validation["invalid_bcf"] > 0:
            print(f"  âš ï¸  BCF ê²€ì¦: ìœ íš¨ {bcf_validation['valid_bcf']}ê°œ, ë¬´íš¨ {bcf_validation['invalid_bcf']}ê°œ")
        
        # ì´ í¬ê¸°
        total_size = sum(f.stat().st_size for f in self.schependomlaan_dir.rglob("*") if f.is_file())
        total_size_mb = total_size / (1024 * 1024)
        print(f"  âœ… ì´ í¬ê¸°: {total_size_mb:.2f} MB")
        
        result = {
            "status": "ok" if len(bcf_files) > 0 else "warning",
            "bcf_count": len(bcf_files),
            "weekly_models_count": len(weekly_models),
            "event_files_count": len(event_files),
            "bcf_validation": bcf_validation,
            "total_size_mb": total_size_mb
        }
        
        self.results["schependomlaan"] = result
        return result
    
    def generate_summary(self) -> Dict:
        """ê²€ì¦ ìš”ì•½ ìƒì„±"""
        print("\nğŸ“Š ê²€ì¦ ìš”ì•½ ìƒì„± ì¤‘...")
        
        slabim = self.results["slabim"]
        duraark = self.results["duraark"]
        schependomlaan = self.results["schependomlaan"]
        
        summary = {
            "total_datasets": 3,
            "datasets_found": sum(1 for d in [slabim, duraark, schependomlaan] if d.get("status") == "ok"),
            "total_files": (
                slabim.get("slam_count", 0) + slabim.get("bim_count", 0) +
                duraark.get("ifc_count", 0) +
                schependomlaan.get("bcf_count", 0) + schependomlaan.get("weekly_models_count", 0)
            ),
            "total_size_mb": (
                slabim.get("total_size_mb", 0) +
                duraark.get("total_size_mb", 0) +
                schependomlaan.get("total_size_mb", 0)
            ),
            "bcf_files_available": schependomlaan.get("bcf_count", 0),
            "error_count": len(self.results["errors"]),
            "warning_count": len(self.results["warnings"])
        }
        
        self.results["summary"] = summary
        
        print(f"\n{'='*60}")
        print("ğŸ¯ ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*60}")
        print(f"ì´ ë°ì´í„°ì…‹: {summary['total_datasets']}ê°œ")
        print(f"í™•ë³´ëœ ë°ì´í„°ì…‹: {summary['datasets_found']}ê°œ")
        print(f"ì´ íŒŒì¼ ìˆ˜: {summary['total_files']}ê°œ")
        print(f"ì´ í¬ê¸°: {summary['total_size_mb']:.2f} MB")
        print(f"BCF íŒŒì¼: {summary['bcf_files_available']}ê°œ")
        print(f"ì˜¤ë¥˜: {summary['error_count']}ê°œ")
        print(f"ê²½ê³ : {summary['warning_count']}ê°œ")
        print(f"{'='*60}")
        
        return summary
    
    def save_report(self, output_path: Path = None):
        """ê²€ì¦ ë³´ê³ ì„œ ì €ì¥"""
        if output_path is None:
            output_path = ACADEMIC_DIR / "validation_report.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²€ì¦ ë³´ê³ ì„œ ì €ì¥: {output_path}")
    
    def print_errors_and_warnings(self):
        """ì˜¤ë¥˜ ë° ê²½ê³  ì¶œë ¥"""
        if self.results["errors"]:
            print(f"\n{'='*60}")
            print("âŒ ì˜¤ë¥˜:")
            print(f"{'='*60}")
            for error in self.results["errors"]:
                print(f"  â€¢ {error}")
        
        if self.results["warnings"]:
            print(f"\n{'='*60}")
            print("âš ï¸  ê²½ê³ :")
            print(f"{'='*60}")
            for warning in self.results["warnings"]:
                print(f"  â€¢ {warning}")
    
    def validate_all(self) -> bool:
        """ì „ì²´ ê²€ì¦ ìˆ˜í–‰"""
        print("ğŸš€ í•™ìˆ  ë°ì´í„°ì…‹ ê²€ì¦ ì‹œì‘...\n")
        
        # ê° ë°ì´í„°ì…‹ ê²€ì¦
        self.validate_slabim_data()
        self.validate_duraark_data()
        self.validate_schependomlaan_data()
        
        # ìš”ì•½ ìƒì„±
        summary = self.generate_summary()
        
        # ì˜¤ë¥˜ ë° ê²½ê³  ì¶œë ¥
        self.print_errors_and_warnings()
        
        # ë³´ê³ ì„œ ì €ì¥
        self.save_report()
        
        # ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
        success = summary["datasets_found"] > 0 and summary["error_count"] == 0
        
        if success:
            print("\nâœ… ê²€ì¦ ì™„ë£Œ - ë°ì´í„° ì‚¬ìš© ê°€ëŠ¥")
            return True
        else:
            print("\nâŒ ê²€ì¦ ì‹¤íŒ¨ - ë°ì´í„° í™•ì¸ í•„ìš”")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    validator = AcademicDataValidator()
    success = validator.validate_all()
    
    if not success:
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. í•™ìˆ  ê¸°ê´€ì— ë°ì´í„° ìš”ì²­")
        print("  2. contact_templates/ ë””ë ‰í† ë¦¬ì˜ ë¬¸ì˜ í…œí”Œë¦¿ ì‚¬ìš©")
        print("  3. ë°ì´í„° ìˆ˜ì‹  í›„ ë‹¤ì‹œ ê²€ì¦ ì‹¤í–‰")
        sys.exit(1)
    else:
        print("\nğŸ‰ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. BCF ë³€í™˜: python scripts/convert_academic_to_bcf.py")
        print("  2. ë°ì´í„° í†µí•©: python scripts/integrate_academic_data.py")
        sys.exit(0)

if __name__ == "__main__":
    main()
