#!/usr/bin/env python3
"""
ìˆ˜ì •ëœ ë°ì´í„°ë¡œ í‰ê°€ í…ŒìŠ¤íŠ¸
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from contextualforget.core.utils import read_jsonl
from contextualforget.baselines.bm25_engine import BM25QueryEngine
from contextualforget.query.contextual_forget_engine import ContextualForgetEngine
from contextualforget.query.adaptive_retrieval import HybridRetrievalEngine
import pickle


def load_fixed_graph():
    """ìˆ˜ì •ëœ ê·¸ë˜í”„ ë¡œë“œ"""
    graph_file = Path("data/processed/real_graph/real_data_graph_with_connections.pkl")
    
    if not graph_file.exists():
        raise FileNotFoundError(f"ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_file}")
    
    with open(graph_file, 'rb') as f:
        graph = pickle.load(f)
    
    print(f"âœ… ìˆ˜ì •ëœ ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ: {graph.number_of_nodes()}ê°œ ë…¸ë“œ, {graph.number_of_edges()}ê°œ ì—°ê²°")
    return graph


def load_fixed_gold_standard():
    """ìˆ˜ì •ëœ Gold Standard ë¡œë“œ"""
    gold_file = Path("eval/gold_standard_fixed.jsonl")
    
    if not gold_file.exists():
        raise FileNotFoundError(f"Gold Standard íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gold_file}")
    
    gold_data = list(read_jsonl(str(gold_file)))
    print(f"âœ… ìˆ˜ì •ëœ Gold Standard ë¡œë“œ ì™„ë£Œ: {len(gold_data)}ê°œ ì§ˆë¬¸")
    return gold_data


def initialize_engines_with_fixed_data():
    """ìˆ˜ì •ëœ ë°ì´í„°ë¡œ ì—”ì§„ ì´ˆê¸°í™”"""
    print("ğŸ”§ ìˆ˜ì •ëœ ë°ì´í„°ë¡œ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    
    # ê·¸ë˜í”„ ë¡œë“œ
    graph = load_fixed_graph()
    
    # ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¡° ìƒì„±
    graph_data = {
        'graph': graph,
        'nodes': list(graph.nodes(data=True))
    }
    
    engines = {}
    
    try:
        # BM25 ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” BM25 ì—”ì§„ ì´ˆê¸°í™”...")
        bm25_engine = BM25QueryEngine('BM25_Fixed')
        bm25_engine.initialize(graph_data)
        engines['BM25'] = bm25_engine
        print("    âœ… BM25 ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ BM25 ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    try:
        # ContextualForget ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” ContextualForget ì—”ì§„ ì´ˆê¸°í™”...")
        cf_engine = ContextualForgetEngine(graph)
        engines['ContextualForget'] = cf_engine
        print("    âœ… ContextualForget ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ ContextualForget ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    try:
        # Hybrid ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” Hybrid ì—”ì§„ ì´ˆê¸°í™”...")
        if 'ContextualForget' in engines and 'BM25' in engines:
            base_engines = {
                'BM25': engines['BM25'],
                'ContextualForget': engines['ContextualForget']
            }
            hybrid_engine = HybridRetrievalEngine(base_engines)
            engines['Hybrid'] = hybrid_engine
            print("    âœ… Hybrid ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ Hybrid ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    print(f"âœ… ì´ {len(engines)}ê°œ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    return engines


def test_engines_with_fixed_data():
    """ìˆ˜ì •ëœ ë°ì´í„°ë¡œ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª ìˆ˜ì •ëœ ë°ì´í„°ë¡œ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. ì—”ì§„ ì´ˆê¸°í™”
    engines = initialize_engines_with_fixed_data()
    
    # 2. Gold Standard ë¡œë“œ
    gold_data = load_fixed_gold_standard()
    
    # 3. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì„ íƒ (ì²˜ìŒ 20ê°œ)
    test_questions = gold_data[:20]
    print(f"ğŸ”¬ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìˆ˜: {len(test_questions)}")
    
    # 4. ê° ì—”ì§„ë³„ í…ŒìŠ¤íŠ¸
    results = {}
    
    for engine_name, engine in engines.items():
        print(f"\nğŸ” {engine_name} ì—”ì§„ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        engine_results = {
            'success_count': 0,
            'total_questions': len(test_questions),
            'confidence_scores': [],
            'entity_counts': [],
            'response_times': [],
            'detailed_results': []
        }
        
        for i, qa in enumerate(test_questions):
            question = qa['question']
            gold_entities = set(qa.get('gold_entities', []))
            
            start_time = time.perf_counter()
            
            try:
                if engine_name == 'ContextualForget':
                    result = engine.contextual_query(question)
                elif engine_name == 'Hybrid':
                    result = engine.query(question)
                else:
                    result = engine.process_query(question)
                
                response_time = time.perf_counter() - start_time
                
                # ê²°ê³¼ ë¶„ì„
                retrieved_entities = set(result.get('entities', []))
                confidence = result.get('confidence', 0.0)
                entity_count = result.get('result_count', 0)
                
                # ì„±ê³µ ì—¬ë¶€ íŒë‹¨ (GUIDê°€ ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ê²½ìš°)
                is_success = len(gold_entities & retrieved_entities) > 0
                
                if is_success:
                    engine_results['success_count'] += 1
                
                engine_results['confidence_scores'].append(confidence)
                engine_results['entity_counts'].append(entity_count)
                engine_results['response_times'].append(response_time)
                
                detailed_result = {
                    'question_id': i + 1,
                    'question': question,
                    'gold_entities': list(gold_entities),
                    'retrieved_entities': list(retrieved_entities),
                    'confidence': confidence,
                    'entity_count': entity_count,
                    'response_time': response_time,
                    'is_success': is_success
                }
                engine_results['detailed_results'].append(detailed_result)
                
                print(f"  ğŸ“ ì§ˆë¬¸ {i+1}: {question[:50]}...")
                print(f"    ğŸ“Š ê²°ê³¼: {entity_count}ê°œ ì—”í‹°í‹°, ì‹ ë¢°ë„ {confidence:.3f}, ì„±ê³µ: {is_success}")
                
            except Exception as e:
                print(f"  âŒ ì§ˆë¬¸ {i+1} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                engine_results['confidence_scores'].append(0.0)
                engine_results['entity_counts'].append(0)
                engine_results['response_times'].append(0.0)
        
        # ì—”ì§„ë³„ í†µê³„ ê³„ì‚°
        success_rate = (engine_results['success_count'] / engine_results['total_questions']) * 100
        avg_confidence = sum(engine_results['confidence_scores']) / len(engine_results['confidence_scores'])
        avg_entities = sum(engine_results['entity_counts']) / len(engine_results['entity_counts'])
        avg_response_time = sum(engine_results['response_times']) / len(engine_results['response_times'])
        
        print(f"  ğŸ“ˆ {engine_name} ê²°ê³¼:")
        print(f"    ì„±ê³µë¥ : {success_rate:.1f}%")
        print(f"    í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"    í‰ê·  ì—”í‹°í‹° ìˆ˜: {avg_entities:.1f}")
        print(f"    ì‹¤í–‰ ì‹œê°„: {avg_response_time:.2f}ì´ˆ")
        
        results[engine_name] = {
            'success_rate': success_rate,
            'avg_confidence': avg_confidence,
            'avg_entities': avg_entities,
            'avg_response_time': avg_response_time,
            'detailed_results': engine_results['detailed_results']
        }
    
    # 5. ê²°ê³¼ ì €ì¥
    output_file = Path("data/analysis/fixed_data_test_results.json")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {output_file}")
    
    # 6. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ìˆ˜ì •ëœ ë°ì´í„° í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    for engine_name, result in results.items():
        print(f"\nğŸ” {engine_name}:")
        print(f"  ì„±ê³µë¥ : {result['success_rate']:.1f}%")
        print(f"  í‰ê·  ì‹ ë¢°ë„: {result['avg_confidence']:.3f}")
        print(f"  í‰ê·  ì—”í‹°í‹° ìˆ˜: {result['avg_entities']:.1f}")
        print(f"  ì‹¤í–‰ ì‹œê°„: {result['avg_response_time']:.2f}ì´ˆ")
    
    print("\n" + "="*60)
    print("ğŸ‰ ìˆ˜ì •ëœ ë°ì´í„° í‰ê°€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ìˆ˜ì •ëœ ë°ì´í„° í‰ê°€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    try:
        results = test_engines_with_fixed_data()
        
        # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
        total_success = sum(result['success_rate'] for result in results.values())
        avg_success = total_success / len(results) if results else 0
        
        print(f"\nğŸ“ˆ ì „ì²´ í‰ê·  ì„±ê³µë¥ : {avg_success:.1f}%")
        
        if avg_success >= 80:
            print("ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥! ëª¨ë“  ì—”ì§„ì´ 80% ì´ìƒ ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.")
        elif avg_success >= 60:
            print("âœ… ì–‘í˜¸í•œ ì„±ëŠ¥! ëŒ€ë¶€ë¶„ì˜ ì—”ì§„ì´ 60% ì´ìƒ ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ê°œì„  í•„ìš”! ì¼ë¶€ ì—”ì§„ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œì•¼ í•©ë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
