#!/usr/bin/env python3
"""
ì§ì ‘ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ í•™ìˆ  ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025-10-15
ìš©ë„: DURAARK, Schependomlaan ë°ì´í„°ì…‹ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
"""

import requests
import json
import time
import os
import zipfile
from pathlib import Path
from typing import Dict, List, Optional
import urllib.parse
from tqdm import tqdm

PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data" / "external" / "academic"
DATA_DIR.mkdir(parents=True, exist_ok=True)

class DatasetDownloader:
    """ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        self.download_results = {}
    
    def download_duraark_dataset(self) -> Dict:
        """DURAARK ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        print("ğŸ“¥ DURAARK ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        result = {
            "status": "downloading",
            "downloaded_files": [],
            "total_size": 0,
            "errors": []
        }
        
        duraark_dir = DATA_DIR / "duraark"
        duraark_dir.mkdir(exist_ok=True)
        
        # DURAARK ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
        try:
            response = self.session.get("http://duraark.eu/", timeout=30)
            if response.status_code == 200:
                # ì›¹ì‚¬ì´íŠ¸ ë‚´ìš©ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                content = response.text.lower()
                
                # ì¼ë°˜ì ì¸ ë‹¤ìš´ë¡œë“œ í‚¤ì›Œë“œ ì°¾ê¸°
                download_keywords = [
                    "download", "data", "dataset", "ifc", "bim", 
                    "medical clinic", "duraark", "zip", "tar.gz"
                ]
                
                # ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ ë§í¬ ì°¾ê¸° ì‹œë„
                import re
                links = re.findall(r'href="([^"]*)"', response.text)
                
                for link in links:
                    if any(keyword in link.lower() for keyword in download_keywords):
                        if link.startswith('/'):
                            full_url = "http://duraark.eu" + link
                        elif link.startswith('http'):
                            full_url = link
                        else:
                            continue
                        
                        try:
                            print(f"ğŸ”— ë‹¤ìš´ë¡œë“œ ì‹œë„: {full_url}")
                            file_response = self.session.get(full_url, timeout=60, stream=True)
                            
                            if file_response.status_code == 200:
                                # íŒŒì¼ëª… ì¶”ì¶œ
                                filename = os.path.basename(urllib.parse.urlparse(full_url).path)
                                if not filename or '.' not in filename:
                                    filename = f"duraark_data_{int(time.time())}.zip"
                                
                                filepath = duraark_dir / filename
                                
                                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                                with open(filepath, 'wb') as f:
                                    for chunk in tqdm(file_response.iter_content(chunk_size=8192), 
                                                    desc=f"ë‹¤ìš´ë¡œë“œ {filename}"):
                                        if chunk:
                                            f.write(chunk)
                                
                                result["downloaded_files"].append(str(filepath))
                                result["total_size"] += filepath.stat().st_size
                                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                                
                        except Exception as e:
                            result["errors"].append(f"ë§í¬ {full_url}: {str(e)}")
                
                # GitHub ë¦¬í¬ì§€í† ë¦¬ í™•ì¸
                github_urls = [
                    "https://github.com/DURAARK",
                    "https://github.com/duraark"
                ]
                
                for github_url in github_urls:
                    try:
                        response = self.session.get(github_url, timeout=30)
                        if response.status_code == 200:
                            # GitHubì—ì„œ ë¦¬í¬ì§€í† ë¦¬ ëª©ë¡ ì°¾ê¸°
                            repos = re.findall(r'href="([^"]*)"', response.text)
                            for repo in repos:
                                if "/DURAARK/" in repo and repo.endswith('"'):
                                    repo_url = "https://github.com" + repo.replace('"', '')
                                    print(f"ğŸ”— GitHub ë¦¬í¬ì§€í† ë¦¬ ë°œê²¬: {repo_url}")
                                    
                                    # ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë¦´ë¦¬ì¦ˆ í™•ì¸
                                    releases_url = repo_url + "/releases"
                                    releases_response = self.session.get(releases_url, timeout=30)
                                    
                                    if releases_response.status_code == 200:
                                        # ë¦´ë¦¬ì¦ˆì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                                        release_links = re.findall(r'href="([^"]*\.(?:zip|tar\.gz|tar\.bz2))"', releases_response.text)
                                        for release_link in release_links:
                                            if release_link.startswith('/'):
                                                download_url = "https://github.com" + release_link
                                            else:
                                                download_url = release_link
                                            
                                            try:
                                                print(f"ğŸ“¦ ë¦´ë¦¬ì¦ˆ ë‹¤ìš´ë¡œë“œ: {download_url}")
                                                file_response = self.session.get(download_url, timeout=120, stream=True)
                                                
                                                if file_response.status_code == 200:
                                                    filename = os.path.basename(urllib.parse.urlparse(download_url).path)
                                                    filepath = duraark_dir / filename
                                                    
                                                    with open(filepath, 'wb') as f:
                                                        for chunk in tqdm(file_response.iter_content(chunk_size=8192), 
                                                                        desc=f"ë‹¤ìš´ë¡œë“œ {filename}"):
                                                            if chunk:
                                                                f.write(chunk)
                                                    
                                                    result["downloaded_files"].append(str(filepath))
                                                    result["total_size"] += filepath.stat().st_size
                                                    print(f"âœ… ë¦´ë¦¬ì¦ˆ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                                                    
                                            except Exception as e:
                                                result["errors"].append(f"ë¦´ë¦¬ì¦ˆ {download_url}: {str(e)}")
                                    
                                    break
                    except Exception as e:
                        result["errors"].append(f"GitHub {github_url}: {str(e)}")
            
        except Exception as e:
            result["errors"].append(f"DURAARK ì›¹ì‚¬ì´íŠ¸ ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")
        
        result["status"] = "completed"
        self.download_results["duraark"] = result
        return result
    
    def download_schependomlaan_dataset(self) -> Dict:
        """Schependomlaan ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        print("ğŸ“¥ Schependomlaan ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        result = {
            "status": "downloading",
            "downloaded_files": [],
            "total_size": 0,
            "errors": []
        }
        
        schependomlaan_dir = DATA_DIR / "schependomlaan"
        schependomlaan_dir.mkdir(exist_ok=True)
        
        # 4TU ë°ì´í„° í¬í„¸ì—ì„œ ê²€ìƒ‰
        try:
            search_url = "https://data.4tu.nl/search?q=schependomlaan"
            response = self.session.get(search_url, timeout=30)
            
            if response.status_code == 200:
                print("ğŸ” 4TU ë°ì´í„° í¬í„¸ì—ì„œ Schependomlaan ê²€ìƒ‰...")
                
                # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                import re
                links = re.findall(r'href="([^"]*)"', response.text)
                
                for link in links:
                    if "schependomlaan" in link.lower() or "bim" in link.lower():
                        if link.startswith('/'):
                            full_url = "https://data.4tu.nl" + link
                        elif link.startswith('http'):
                            full_url = link
                        else:
                            continue
                        
                        try:
                            print(f"ğŸ”— ë°ì´í„°ì…‹ í˜ì´ì§€ í™•ì¸: {full_url}")
                            page_response = self.session.get(full_url, timeout=30)
                            
                            if page_response.status_code == 200:
                                # í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                                download_links = re.findall(r'href="([^"]*\.(?:zip|tar\.gz|bcf|ifc))"', page_response.text)
                                
                                for download_link in download_links:
                                    if download_link.startswith('/'):
                                        download_url = "https://data.4tu.nl" + download_link
                                    else:
                                        download_url = download_link
                                    
                                    try:
                                        print(f"ğŸ“¦ ë‹¤ìš´ë¡œë“œ ì‹œë„: {download_url}")
                                        file_response = self.session.get(download_url, timeout=120, stream=True)
                                        
                                        if file_response.status_code == 200:
                                            filename = os.path.basename(urllib.parse.urlparse(download_url).path)
                                            if not filename or '.' not in filename:
                                                filename = f"schependomlaan_data_{int(time.time())}.zip"
                                            
                                            filepath = schependomlaan_dir / filename
                                            
                                            with open(filepath, 'wb') as f:
                                                for chunk in tqdm(file_response.iter_content(chunk_size=8192), 
                                                                desc=f"ë‹¤ìš´ë¡œë“œ {filename}"):
                                                    if chunk:
                                                        f.write(chunk)
                                            
                                            result["downloaded_files"].append(str(filepath))
                                            result["total_size"] += filepath.stat().st_size
                                            print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                                            
                                    except Exception as e:
                                        result["errors"].append(f"ë‹¤ìš´ë¡œë“œ {download_url}: {str(e)}")
                                
                                break
                        except Exception as e:
                            result["errors"].append(f"í˜ì´ì§€ {full_url}: {str(e)}")
            
        except Exception as e:
            result["errors"].append(f"4TU ë°ì´í„° í¬í„¸ ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")
        
        # GitHubì—ì„œë„ ê²€ìƒ‰
        try:
            github_search_url = "https://github.com/search?q=schependomlaan"
            response = self.session.get(github_search_url, timeout=30)
            
            if response.status_code == 200:
                print("ğŸ” GitHubì—ì„œ Schependomlaan ê²€ìƒ‰...")
                
                import re
                repo_links = re.findall(r'href="([^"]*)"', response.text)
                
                for repo_link in repo_links:
                    if "/schependomlaan" in repo_link and repo_link.endswith('"'):
                        repo_url = "https://github.com" + repo_link.replace('"', '')
                        print(f"ğŸ”— GitHub ë¦¬í¬ì§€í† ë¦¬ ë°œê²¬: {repo_url}")
                        
                        try:
                            # ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë¦´ë¦¬ì¦ˆ í™•ì¸
                            releases_url = repo_url + "/releases"
                            releases_response = self.session.get(releases_url, timeout=30)
                            
                            if releases_response.status_code == 200:
                                release_links = re.findall(r'href="([^"]*\.(?:zip|tar\.gz))"', releases_response.text)
                                for release_link in release_links:
                                    if release_link.startswith('/'):
                                        download_url = "https://github.com" + release_link
                                    else:
                                        download_url = release_link
                                    
                                    try:
                                        print(f"ğŸ“¦ GitHub ë¦´ë¦¬ì¦ˆ ë‹¤ìš´ë¡œë“œ: {download_url}")
                                        file_response = self.session.get(download_url, timeout=120, stream=True)
                                        
                                        if file_response.status_code == 200:
                                            filename = os.path.basename(urllib.parse.urlparse(download_url).path)
                                            filepath = schependomlaan_dir / filename
                                            
                                            with open(filepath, 'wb') as f:
                                                for chunk in tqdm(file_response.iter_content(chunk_size=8192), 
                                                                desc=f"ë‹¤ìš´ë¡œë“œ {filename}"):
                                                    if chunk:
                                                        f.write(chunk)
                                            
                                            result["downloaded_files"].append(str(filepath))
                                            result["total_size"] += filepath.stat().st_size
                                            print(f"âœ… GitHub ë¦´ë¦¬ì¦ˆ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                                            
                                    except Exception as e:
                                        result["errors"].append(f"GitHub ë¦´ë¦¬ì¦ˆ {download_url}: {str(e)}")
                            
                        except Exception as e:
                            result["errors"].append(f"GitHub ë¦¬í¬ì§€í† ë¦¬ {repo_url}: {str(e)}")
                        
                        break
        except Exception as e:
            result["errors"].append(f"GitHub ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        result["status"] = "completed"
        self.download_results["schependomlaan"] = result
        return result
    
    def extract_downloaded_files(self):
        """ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì••ì¶• í•´ì œ"""
        print("ğŸ“¦ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì••ì¶• í•´ì œ...")
        
        for dataset, result in self.download_results.items():
            if not result.get("downloaded_files"):
                continue
            
            dataset_dir = DATA_DIR / dataset
            extracted_dir = dataset_dir / "extracted"
            extracted_dir.mkdir(exist_ok=True)
            
            for filepath in result["downloaded_files"]:
                file_path = Path(filepath)
                
                if file_path.suffix.lower() in ['.zip']:
                    try:
                        print(f"ğŸ“‚ ì••ì¶• í•´ì œ: {file_path.name}")
                        with zipfile.ZipFile(file_path, 'r') as zip_ref:
                            zip_ref.extractall(extracted_dir)
                        print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {file_path.name}")
                    except Exception as e:
                        print(f"âŒ ì••ì¶• í•´ì œ ì‹¤íŒ¨: {file_path.name} - {str(e)}")
    
    def generate_download_report(self):
        """ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        report_file = DATA_DIR / "DOWNLOAD_RESULTS.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ì§ì ‘ ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ë³´ê³ ì„œ\n\n")
            f.write("**ì‘ì„±ì¼**: 2025ë…„ 10ì›” 15ì¼\n\n")
            
            f.write("## ë‹¤ìš´ë¡œë“œ ê²°ê³¼\n\n")
            
            for dataset, result in self.download_results.items():
                f.write(f"### {dataset.upper()}\n")
                f.write(f"- **ìƒíƒœ**: {result['status']}\n")
                f.write(f"- **ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ìˆ˜**: {len(result['downloaded_files'])}\n")
                f.write(f"- **ì´ í¬ê¸°**: {result['total_size'] / (1024*1024):.2f} MB\n")
                
                if result["downloaded_files"]:
                    f.write("- **ë‹¤ìš´ë¡œë“œëœ íŒŒì¼**:\n")
                    for filepath in result["downloaded_files"]:
                        f.write(f"  - {filepath}\n")
                
                if result["errors"]:
                    f.write("- **ì˜¤ë¥˜**:\n")
                    for error in result["errors"]:
                        f.write(f"  - {error}\n")
                
                f.write("\n")
            
            f.write("## ë‹¤ìŒ ë‹¨ê³„\n\n")
            f.write("1. ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²€ì¦\n")
            f.write("2. IFC/BCF íŒŒì¼ ì¶”ì¶œ\n")
            f.write("3. ë°ì´í„° í’ˆì§ˆ í‰ê°€\n")
            f.write("4. í”„ë¡œì íŠ¸ í†µí•©\n")
        
        print(f"ğŸ“„ ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±: {report_file}")
    
    def run_download(self):
        """ì „ì²´ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
        print("ğŸš€ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\n")
        
        # DURAARK ë‹¤ìš´ë¡œë“œ
        self.download_duraark_dataset()
        
        # Schependomlaan ë‹¤ìš´ë¡œë“œ
        self.download_schependomlaan_dataset()
        
        # ì••ì¶• í•´ì œ
        self.extract_downloaded_files()
        
        # ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±
        self.generate_download_report()
        
        print("\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        
        # ìš”ì•½ ì¶œë ¥
        total_files = sum(len(result.get("downloaded_files", [])) for result in self.download_results.values())
        total_size = sum(result.get("total_size", 0) for result in self.download_results.values())
        
        print(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ìš”ì•½:")
        print(f"   - ì´ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼: {total_files}ê°œ")
        print(f"   - ì´ í¬ê¸°: {total_size / (1024*1024):.2f} MB")
        
        for dataset, result in self.download_results.items():
            print(f"   - {dataset}: {len(result.get('downloaded_files', []))}ê°œ íŒŒì¼")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    downloader = DatasetDownloader()
    downloader.run_download()

if __name__ == "__main__":
    main()
