"""
ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
ê·¸ë˜í”„ì—ì„œ IFC/BCF ëŒ€í‘œ ë…¸ë“œ 100ê°œ ì¶”ì¶œ (LLM QA ìƒì„±ìš©)
"""
import argparse
import json
import pickle
import sys
from collections import Counter
from pathlib import Path

import networkx as nx

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))


def extract_representative_samples(graph_path: str, output_path: str):
    """
    ê·¸ë˜í”„ì—ì„œ ëŒ€í‘œ ìƒ˜í”Œì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ëª©í‘œ:
    - IFC ì—”í‹°í‹° ìƒ˜í”Œ: 30ê°œ
    - BCF ì´ìŠˆ ìƒ˜í”Œ: 30ê°œ
    - ì—°ê²°ëœ ìŒ (BCF-IFC): 40ê°œ
    
    ì´ 100ê°œ ìƒ˜í”Œ ìƒì„±
    """
    print(f"ğŸ“Š ê·¸ë˜í”„ ë¡œë“œ ì¤‘: {graph_path}")
    with open(graph_path, 'rb') as f:
        G = pickle.load(f)
    
    print(f"   ë…¸ë“œ: {G.number_of_nodes():,}ê°œ")
    print(f"   ì—£ì§€: {G.number_of_edges():,}ê°œ")
    
    # IFC ë…¸ë“œ ì¶”ì¶œ
    ifc_nodes = [n for n in G.nodes if isinstance(n, tuple) and n[0] == 'IFC']
    bcf_nodes = [n for n in G.nodes if isinstance(n, tuple) and n[0] == 'BCF']
    
    print(f"\nğŸ·ï¸  ë…¸ë“œ íƒ€ì…:")
    print(f"   IFC: {len(ifc_nodes):,}ê°œ")
    print(f"   BCF: {len(bcf_nodes):,}ê°œ")
    
    # 1. IFC íƒ€ì…ë³„ ëŒ€í‘œ ë…¸ë“œ (30ê°œ)
    print(f"\nğŸ“¦ IFC íƒ€ì…ë³„ ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ì¤‘...")
    ifc_types = Counter([
        G.nodes[n].get('type', 'Unknown')
        for n in ifc_nodes
    ])
    
    ifc_samples = []
    for ifc_type, count in ifc_types.most_common(10):
        nodes = [n for n in ifc_nodes if G.nodes[n].get('type') == ifc_type]
        # íƒ€ì…ë‹¹ ìµœëŒ€ 3ê°œ
        for node in nodes[:3]:
            node_data = G.nodes[node]
            ifc_samples.append({
                'node_id': node,
                'guid': node[1],
                'type': node_data.get('type', 'Unknown'),
                'name': node_data.get('name', ''),
                'description': node_data.get('description', ''),
                'sample_type': 'entity_search'
            })
    
    print(f"   âœ… IFC ìƒ˜í”Œ: {len(ifc_samples)}ê°œ")
    
    # 2. BCF ì´ìŠˆ ìƒ˜í”Œ (30ê°œ)
    print(f"\nğŸ“‹ BCF ì´ìŠˆ ìƒ˜í”Œ ì¶”ì¶œ ì¤‘...")
    
    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì¶”ì¶œ
    priorities = ['critical', 'major', 'high', 'medium', 'normal', 'minor', 'low']
    bcf_by_priority = {p: [] for p in priorities}
    bcf_no_priority = []
    
    for node in bcf_nodes:
        node_data = G.nodes[node]
        priority = node_data.get('priority', '').lower()
        
        if priority in bcf_by_priority:
            bcf_by_priority[priority].append(node)
        else:
            bcf_no_priority.append(node)
    
    bcf_samples = []
    
    # ê° ìš°ì„ ìˆœìœ„ë³„ë¡œ 5ê°œì”©
    for priority in priorities:
        for node in bcf_by_priority[priority][:5]:
            node_data = G.nodes[node]
            bcf_samples.append({
                'node_id': node,
                'topic_id': node[1],
                'title': node_data.get('title', ''),
                'description': node_data.get('description', ''),
                'priority': node_data.get('priority', ''),
                'author': node_data.get('author', ''),
                'created': node_data.get('created', ''),
                'sample_type': 'issue_search'
            })
    
    # ë¶€ì¡±í•˜ë©´ ìš°ì„ ìˆœìœ„ ì—†ëŠ” ê²ƒì—ì„œ ì±„ìš°ê¸°
    if len(bcf_samples) < 30:
        for node in bcf_no_priority[:30 - len(bcf_samples)]:
            node_data = G.nodes[node]
            bcf_samples.append({
                'node_id': node,
                'topic_id': node[1],
                'title': node_data.get('title', ''),
                'description': node_data.get('description', ''),
                'priority': node_data.get('priority', 'normal'),
                'author': node_data.get('author', ''),
                'created': node_data.get('created', ''),
                'sample_type': 'issue_search'
            })
    
    print(f"   âœ… BCF ìƒ˜í”Œ: {len(bcf_samples)}ê°œ")
    
    # 3. ì—°ê²°ëœ ìŒ (BCF â†’ IFC) (40ê°œ)
    print(f"\nğŸ”— ì—°ê²°ëœ BCF-IFC ìŒ ì¶”ì¶œ ì¤‘...")
    connected_pairs = []
    
    for bcf_node in bcf_nodes[:200]:  # ì²˜ìŒ 200ê°œ BCF ë…¸ë“œ ê²€ì‚¬
        successors = list(G.successors(bcf_node))
        
        if successors:
            # ì²« ë²ˆì§¸ ì—°ê²°ëœ IFC ë…¸ë“œ
            ifc_node = successors[0]
            edge_data = G.edges.get((bcf_node, ifc_node), {})
            
            bcf_data = G.nodes[bcf_node]
            ifc_data = G.nodes[ifc_node]
            
            connected_pairs.append({
                'bcf_node_id': bcf_node,
                'ifc_node_id': ifc_node,
                'bcf_topic_id': bcf_node[1],
                'bcf_title': bcf_data.get('title', ''),
                'bcf_description': bcf_data.get('description', ''),
                'ifc_guid': ifc_node[1],
                'ifc_type': ifc_data.get('type', ''),
                'ifc_name': ifc_data.get('name', ''),
                'confidence': edge_data.get('confidence', 0.5),
                'sample_type': 'relationship'
            })
            
            if len(connected_pairs) >= 40:
                break
    
    print(f"   âœ… ì—°ê²° ìŒ: {len(connected_pairs)}ê°œ")
    
    # ê²°ê³¼ í†µí•©
    samples = {
        'ifc_samples': ifc_samples[:30],
        'bcf_samples': bcf_samples[:30],
        'connected_pairs': connected_pairs[:40],
        'metadata': {
            'total_samples': len(ifc_samples[:30]) + len(bcf_samples[:30]) + len(connected_pairs[:40]),
            'graph_nodes': G.number_of_nodes(),
            'graph_edges': G.number_of_edges(),
            'ifc_node_count': len(ifc_nodes),
            'bcf_node_count': len(bcf_nodes)
        }
    }
    
    # ì €ì¥
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(samples, f, indent=2, ensure_ascii=False)
    
    # í†µê³„ ì¶œë ¥
    total = samples['metadata']['total_samples']
    print(f"\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ:")
    print(f"   IFC ìƒ˜í”Œ: {len(samples['ifc_samples'])}ê°œ")
    print(f"   BCF ìƒ˜í”Œ: {len(samples['bcf_samples'])}ê°œ")
    print(f"   ì—°ê²° ìŒ: {len(samples['connected_pairs'])}ê°œ")
    print(f"   ì´ ìƒ˜í”Œ: {total}ê°œ")
    
    print(f"\nâœ… ìƒ˜í”Œ ì €ì¥: {output_path}")
    
    return samples


def main():
    ap = argparse.ArgumentParser(description='ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ')
    ap.add_argument("--graph", default="data/processed/graph.gpickle", help="ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ")
    ap.add_argument("--output", default="data/processed/representative_samples.json", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    a = ap.parse_args()
    
    samples = extract_representative_samples(a.graph, a.output)
    
    if samples['metadata']['total_samples'] >= 100:
        print(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±: {samples['metadata']['total_samples']}ê°œ >= 100ê°œ")
    else:
        print(f"\nâš ï¸  ëª©í‘œ ë¯¸ë‹¬: {samples['metadata']['total_samples']}ê°œ < 100ê°œ")


if __name__ == "__main__":
    main()

