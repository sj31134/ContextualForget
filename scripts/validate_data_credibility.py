#!/usr/bin/env python3
"""ë°ì´í„° ì‹ ë¢°ì„± ë° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸"""

import json
import sys
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import hashlib


class DataCredibilityValidator:
    """ë°ì´í„° ì‹ ë¢°ì„± ê²€ì¦ê¸°"""
    
    def __init__(self, base_dir: Path):
        self.base_dir = Path(base_dir)
        self.raw_dir = self.base_dir / "data" / "raw" / "downloaded"
        self.data_dir = self.base_dir / "data"
        self.analysis_dir = self.base_dir / "data" / "analysis"
        
        self.validation_report = {
            "timestamp": datetime.now().isoformat(),
            "data_sources": {},
            "quality_metrics": {},
            "credibility_score": 0,
            "issues": [],
            "recommendations": []
        }
    
    def classify_data_sources(self):
        """ë°ì´í„° ì¶œì²˜ ë¶„ë¥˜"""
        print("=" * 70)
        print("ğŸ“‹ ë°ì´í„° ì¶œì²˜ ë¶„ë¥˜ ë° ì‹ ë¢°ë„ í‰ê°€")
        print("=" * 70)
        
        # IFC íŒŒì¼ ë¶„ë¥˜
        ifc_files = list(self.raw_dir.glob("*.ifc")) + list(self.data_dir.glob("*.ifc"))
        
        sources = {
            "buildingsmart": {"files": [], "credibility": "HIGH", "description": "Official buildingSMART samples"},
            "ifcopenshell": {"files": [], "credibility": "MEDIUM", "description": "IFC engine test files"},
            "xbim": {"files": [], "credibility": "MEDIUM", "description": "xBIM sample files"},
            "bimserver": {"files": [], "credibility": "MEDIUM", "description": "BIMserver samples"},
            "synthetic": {"files": [], "credibility": "LOW", "description": "Synthetically generated"},
            "unknown": {"files": [], "credibility": "UNKNOWN", "description": "Unknown source"}
        }
        
        for ifc_file in ifc_files:
            name = ifc_file.name.lower()
            classified = False
            
            if "buildingsmart" in name:
                sources["buildingsmart"]["files"].append(str(ifc_file))
                classified = True
            elif "ifcopenshell" in name:
                sources["ifcopenshell"]["files"].append(str(ifc_file))
                classified = True
            elif "xbim" in name:
                sources["xbim"]["files"].append(str(ifc_file))
                classified = True
            elif "bimserver" in name:
                sources["bimserver"]["files"].append(str(ifc_file))
                classified = True
            elif any(x in name for x in ["residential", "office", "industrial", "hospital", "school"]):
                sources["synthetic"]["files"].append(str(ifc_file))
                classified = True
            
            if not classified:
                sources["unknown"]["files"].append(str(ifc_file))
        
        # BCF íŒŒì¼ ë¶„ë¥˜
        bcf_files = list(self.raw_dir.glob("*.bcf*")) + list((self.data_dir / "raw").glob("*.bcf*"))
        
        bcf_sources = {
            "buildingsmart": [],
            "synthetic": []
        }
        
        for bcf_file in bcf_files:
            name = bcf_file.name.lower()
            if "buildingsmart" in name or "sample.bcf" in name:
                bcf_sources["buildingsmart"].append(str(bcf_file))
            else:
                bcf_sources["synthetic"].append(str(bcf_file))
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“ **IFC íŒŒì¼ ì¶œì²˜ ë¶„í¬**:")
        total_ifc = 0
        for source, data in sources.items():
            count = len(data["files"])
            total_ifc += count
            if count > 0:
                print(f"  {source.upper():15s}: {count:3d}ê°œ - ì‹ ë¢°ë„: {data['credibility']:7s} - {data['description']}")
        
        print(f"\nğŸ“‹ **BCF íŒŒì¼ ì¶œì²˜ ë¶„í¬**:")
        for source, files in bcf_sources.items():
            count = len(files)
            cred = "HIGH" if source == "buildingsmart" else "LOW"
            print(f"  {source.upper():15s}: {count:3d}ê°œ - ì‹ ë¢°ë„: {cred}")
        
        # ì €ì¥
        self.validation_report["data_sources"] = {
            "ifc": sources,
            "bcf": bcf_sources,
            "ifc_total": total_ifc,
            "bcf_total": len(bcf_files)
        }
        
        # ì‹ ë¢°ë„ ì´ìŠˆ ì²´í¬
        if sources["synthetic"]["files"]:
            self.validation_report["issues"].append({
                "severity": "HIGH",
                "category": "data_source",
                "message": f"{len(sources['synthetic']['files'])} synthetic IFC files require validation",
                "impact": "Paper reviewers may question data authenticity"
            })
        
        if len(bcf_sources["synthetic"]) > len(bcf_sources["buildingsmart"]):
            self.validation_report["issues"].append({
                "severity": "CRITICAL",
                "category": "data_source",
                "message": f"{len(bcf_sources['synthetic'])} synthetic BCF files (vs {len(bcf_sources['buildingsmart'])} real)",
                "impact": "Major concern for paper acceptance"
            })
        
        return sources, bcf_sources
    
    def measure_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ ì¸¡ì •"""
        print("\n" + "=" * 70)
        print("ğŸ” ë°ì´í„° í’ˆì§ˆ ì¸¡ì •")
        print("=" * 70)
        
        metrics = {
            "ifc_files_checked": 0,
            "ifc_valid": 0,
            "ifc_invalid": 0,
            "bcf_files_checked": 0,
            "bcf_valid": 0,
            "bcf_invalid": 0,
            "duplicates": 0
        }
        
        # IFC íŒŒì¼ ê¸°ë³¸ ê²€ì¦
        ifc_files = list(self.raw_dir.glob("*.ifc")) + list(self.data_dir.glob("*.ifc"))
        file_hashes = set()
        
        print(f"\nğŸ“ IFC íŒŒì¼ ê²€ì¦ ì¤‘...")
        for ifc_file in ifc_files:
            metrics["ifc_files_checked"] += 1
            
            # ê¸°ë³¸ ìœ íš¨ì„±: íŒŒì¼ ì½ê¸° ê°€ëŠ¥ + "IFC" í—¤ë”
            try:
                with open(ifc_file, 'r', encoding='utf-8', errors='ignore') as f:
                    first_line = f.readline()
                    if "ISO-10303-21" in first_line or "IFC" in first_line:
                        metrics["ifc_valid"] += 1
                    else:
                        metrics["ifc_invalid"] += 1
                
                # ì¤‘ë³µ ì²´í¬ (í•´ì‹œ)
                with open(ifc_file, 'rb') as f:
                    file_hash = hashlib.md5(f.read()).hexdigest()
                    if file_hash in file_hashes:
                        metrics["duplicates"] += 1
                    file_hashes.add(file_hash)
                
            except Exception as e:
                metrics["ifc_invalid"] += 1
                print(f"  âŒ {ifc_file.name}: {e}")
        
        print(f"  âœ… ìœ íš¨: {metrics['ifc_valid']}/{metrics['ifc_files_checked']}")
        print(f"  âŒ ë¬´íš¨: {metrics['ifc_invalid']}/{metrics['ifc_files_checked']}")
        print(f"  ğŸ” ì¤‘ë³µ: {metrics['duplicates']}")
        
        # BCF íŒŒì¼ ê²€ì¦
        bcf_files = list(self.raw_dir.glob("*.bcf*")) + list((self.data_dir / "raw").glob("*.bcf*"))
        
        print(f"\nğŸ“‹ BCF íŒŒì¼ ê²€ì¦ ì¤‘...")
        for bcf_file in bcf_files:
            metrics["bcf_files_checked"] += 1
            
            # ê¸°ë³¸ ìœ íš¨ì„±: ZIP íŒŒì¼ ì½ê¸° ê°€ëŠ¥
            try:
                import zipfile
                with zipfile.ZipFile(bcf_file, 'r') as z:
                    if "bcf.version" in z.namelist():
                        metrics["bcf_valid"] += 1
                    else:
                        metrics["bcf_invalid"] += 1
            except Exception as e:
                metrics["bcf_invalid"] += 1
                print(f"  âŒ {bcf_file.name}: {e}")
        
        print(f"  âœ… ìœ íš¨: {metrics['bcf_valid']}/{metrics['bcf_files_checked']}")
        print(f"  âŒ ë¬´íš¨: {metrics['bcf_invalid']}/{metrics['bcf_files_checked']}")
        
        self.validation_report["quality_metrics"] = metrics
        
        # í’ˆì§ˆ ì´ìŠˆ ì²´í¬
        if metrics["ifc_invalid"] > 0:
            self.validation_report["issues"].append({
                "severity": "MEDIUM",
                "category": "data_quality",
                "message": f"{metrics['ifc_invalid']} invalid IFC files detected",
                "impact": "Data quality concerns"
            })
        
        if metrics["duplicates"] > 10:
            self.validation_report["issues"].append({
                "severity": "LOW",
                "category": "data_quality",
                "message": f"{metrics['duplicates']} duplicate files found",
                "impact": "Inflated data count"
            })
        
        return metrics
    
    def calculate_credibility_score(self):
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°")
        print("=" * 70)
        
        score = 100
        
        sources = self.validation_report["data_sources"]
        
        # IFC ì¶œì²˜ë³„ ê°€ì¤‘ì¹˜
        ifc_sources = sources["ifc"]
        total_ifc = sources["ifc_total"]
        
        if total_ifc > 0:
            buildingsmart_ratio = len(ifc_sources["buildingsmart"]["files"]) / total_ifc
            synthetic_ratio = len(ifc_sources["synthetic"]["files"]) / total_ifc
            
            # buildingSMART ë§ì„ìˆ˜ë¡ +ì ìˆ˜
            score += buildingsmart_ratio * 20
            
            # í•©ì„± ë°ì´í„° ë§ì„ìˆ˜ë¡ -ì ìˆ˜
            score -= synthetic_ratio * 30
        
        # BCF ì¶œì²˜ë³„ ê°€ì¤‘ì¹˜
        bcf_sources = sources["bcf"]
        total_bcf = sources["bcf_total"]
        
        if total_bcf > 0:
            synthetic_bcf_ratio = len(bcf_sources["synthetic"]) / total_bcf
            
            # í•©ì„± BCF ë§ì„ìˆ˜ë¡ í° ê°ì 
            score -= synthetic_bcf_ratio * 40
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­
        metrics = self.validation_report["quality_metrics"]
        if metrics["ifc_files_checked"] > 0:
            valid_ratio = metrics["ifc_valid"] / metrics["ifc_files_checked"]
            score *= valid_ratio
        
        # ì´ìŠˆë³„ ê°ì 
        for issue in self.validation_report["issues"]:
            if issue["severity"] == "CRITICAL":
                score -= 20
            elif issue["severity"] == "HIGH":
                score -= 10
            elif issue["severity"] == "MEDIUM":
                score -= 5
        
        # 0-100 ë²”ìœ„ë¡œ ì œí•œ
        score = max(0, min(100, score))
        
        self.validation_report["credibility_score"] = round(score, 1)
        
        # ë“±ê¸‰
        if score >= 80:
            grade = "âœ… HIGH - Top-tier conference ready"
        elif score >= 60:
            grade = "ğŸŸ¡ MEDIUM - Revision needed"
        elif score >= 40:
            grade = "ğŸŸ  LOW - Major revision required"
        else:
            grade = "ğŸ”´ CRITICAL - Data collection restart recommended"
        
        print(f"\nğŸ¯ **ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜**: {score:.1f}/100")
        print(f"ğŸ“ˆ **ë“±ê¸‰**: {grade}")
        
        return score, grade
    
    def generate_recommendations(self):
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        print("\n" + "=" * 70)
        print("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­")
        print("=" * 70)
        
        recommendations = []
        score = self.validation_report["credibility_score"]
        
        # ì ìˆ˜ë³„ ê¶Œì¥ì‚¬í•­
        if score < 60:
            recommendations.append({
                "priority": "CRITICAL",
                "action": "Reduce synthetic data proportion",
                "details": "Replace synthetic BCF files with real project data or academic datasets",
                "timeline": "2-4 weeks"
            })
        
        if score < 80:
            recommendations.append({
                "priority": "HIGH",
                "action": "Expert validation of synthetic data",
                "details": "Have 2-3 BIM domain experts review and validate synthetic BCF issues",
                "timeline": "1 week"
            })
        
        # í•©ì„± ë°ì´í„° ê´€ë ¨
        sources = self.validation_report["data_sources"]
        if len(sources["bcf"]["synthetic"]) > 30:
            recommendations.append({
                "priority": "HIGH",
                "action": "Document synthetic data generation",
                "details": "Write detailed methodology section explaining BCF generation process",
                "timeline": "3 days"
            })
            
            recommendations.append({
                "priority": "MEDIUM",
                "action": "Fix random seed for reproducibility",
                "details": "Regenerate all synthetic data with fixed seed values",
                "timeline": "1 day"
            })
        
        # Ground truth
        recommendations.append({
            "priority": "HIGH",
            "action": "Create gold standard QA dataset",
            "details": "Generate 50-100 question-answer pairs with expert validation",
            "timeline": "1-2 weeks"
        })
        
        # ì‹¤ì œ ë°ì´í„° í™•ë³´
        recommendations.append({
            "priority": "MEDIUM",
            "action": "Apply for academic datasets",
            "details": "Submit data access requests to BIMPROVE, TU Delft, Stanford repositories",
            "timeline": "2-4 weeks"
        })
        
        # Limitation ì„¹ì…˜
        recommendations.append({
            "priority": "MEDIUM",
            "action": "Write limitations section",
            "details": "Clearly state data sources, synthetic data rationale, and generalizability",
            "timeline": "2 days"
        })
        
        # ì¶œë ¥
        print()
        for i, rec in enumerate(recommendations, 1):
            priority_emoji = {
                "CRITICAL": "ğŸ”´",
                "HIGH": "ğŸŸ¡",
                "MEDIUM": "ğŸŸ ",
                "LOW": "ğŸŸ¢"
            }
            emoji = priority_emoji.get(rec["priority"], "âšª")
            
            print(f"{emoji} {i}. [{rec['priority']}] {rec['action']}")
            print(f"   ì„¤ëª…: {rec['details']}")
            print(f"   ì˜ˆìƒ ì†Œìš”: {rec['timeline']}")
            print()
        
        self.validation_report["recommendations"] = recommendations
        
        return recommendations
    
    def save_report(self):
        """ê²€ì¦ ë³´ê³ ì„œ ì €ì¥"""
        report_path = self.analysis_dir / "credibility_validation_report.json"
        with open(report_path, 'w') as f:
            json.dump(self.validation_report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ê²€ì¦ ë³´ê³ ì„œ ì €ì¥: {report_path}")
        
        # Markdown ìš”ì•½
        md_path = self.analysis_dir / "CREDIBILITY_REPORT.md"
        score = self.validation_report["credibility_score"]
        
        with open(md_path, 'w') as f:
            f.write(f"""# ë°ì´í„° ì‹ ë¢°ì„± ê²€ì¦ ë³´ê³ ì„œ

ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜: {score}/100

""")
            
            if score >= 80:
                f.write("**ë“±ê¸‰**: âœ… HIGH - Top-tier í•™íšŒ ì¤€ë¹„ ì™„ë£Œ\n\n")
            elif score >= 60:
                f.write("**ë“±ê¸‰**: ğŸŸ¡ MEDIUM - ë³´ì™„ ì‘ì—… í•„ìš”\n\n")
            elif score >= 40:
                f.write("**ë“±ê¸‰**: ğŸŸ  LOW - ì£¼ìš” ë³´ì™„ í•„ìš”\n\n")
            else:
                f.write("**ë“±ê¸‰**: ğŸ”´ CRITICAL - ë°ì´í„° ì¬ìˆ˜ì§‘ ê¶Œì¥\n\n")
            
            # ì´ìŠˆ
            if self.validation_report["issues"]:
                f.write("## âš ï¸ ë°œê²¬ëœ ì´ìŠˆ\n\n")
                for issue in self.validation_report["issues"]:
                    f.write(f"- **[{issue['severity']}]** {issue['message']}\n")
                    f.write(f"  - ì˜í–¥: {issue['impact']}\n\n")
            
            # ê¶Œì¥ì‚¬í•­
            f.write("## ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­\n\n")
            for i, rec in enumerate(self.validation_report["recommendations"], 1):
                f.write(f"{i}. **[{rec['priority']}]** {rec['action']}\n")
                f.write(f"   - {rec['details']}\n")
                f.write(f"   - ì˜ˆìƒ ì†Œìš”: {rec['timeline']}\n\n")
        
        print(f"âœ… Markdown ìš”ì•½ ì €ì¥: {md_path}")
        
        return report_path


def main():
    base_dir = Path(__file__).parent.parent
    validator = DataCredibilityValidator(base_dir)
    
    print("ğŸ”¬ ContextualForget ë°ì´í„° ì‹ ë¢°ì„± ê²€ì¦")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # 1. ë°ì´í„° ì¶œì²˜ ë¶„ë¥˜
    sources, bcf_sources = validator.classify_data_sources()
    
    # 2. ë°ì´í„° í’ˆì§ˆ ì¸¡ì •
    metrics = validator.measure_data_quality()
    
    # 3. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
    score, grade = validator.calculate_credibility_score()
    
    # 4. ê¶Œì¥ì‚¬í•­ ìƒì„±
    recommendations = validator.generate_recommendations()
    
    # 5. ë³´ê³ ì„œ ì €ì¥
    validator.save_report()
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“ ìµœì¢… ìš”ì•½")
    print("=" * 70)
    print(f"""
ğŸ¯ ì‹ ë¢°ë„ ì ìˆ˜: {score}/100
ğŸ“ˆ ë“±ê¸‰: {grade}
âš ï¸  ë°œê²¬ëœ ì´ìŠˆ: {len(validator.validation_report['issues'])}ê°œ
ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜: {len(recommendations)}ê°œ

ìƒì„¸ ë³´ê³ ì„œ:
  - data/analysis/credibility_validation_report.json
  - data/analysis/CREDIBILITY_REPORT.md
  - docs/DATA_CREDIBILITY_ASSESSMENT.md
""")
    
    # ì¢…ë£Œ ì½”ë“œ
    if score >= 60:
        print("âœ… ë…¼ë¬¸ ì§„í–‰ ê°€ëŠ¥ (ë³´ì™„ ì‘ì—… ë³‘í–‰)")
        return 0
    else:
        print("âš ï¸  ë°ì´í„° ì‹ ë¢°ì„± ë³´ê°• í›„ ì§„í–‰ ê¶Œì¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())

