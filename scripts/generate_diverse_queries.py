#!/usr/bin/env python3
"""
ë‹¤ì–‘í•œ ì¿¼ë¦¬ íƒ€ì… Gold Standard ìƒì„± ìŠ¤í¬ë¦½íŠ¸
6ê°€ì§€ ì¿¼ë¦¬ íƒ€ì…ìœ¼ë¡œ 500ê°œ ì§ˆì˜ ìƒì„±
"""

import sys
import json
import random
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from contextualforget.core.utils import read_jsonl, write_jsonl


def load_integrated_data():
    """í†µí•© ë°ì´í„°ì…‹ ë¡œë“œ"""
    
    print("ğŸ“‚ í†µí•© ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    
    # í†µí•© BCF ë°ì´í„° ë¡œë“œ
    bcf_file = Path("data/processed/integrated_dataset/integrated_bcf_data.jsonl")
    if not bcf_file.exists():
        print("âŒ í†µí•© BCF ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    bcf_data = list(read_jsonl(str(bcf_file)))
    print(f"  âœ… BCF ë°ì´í„°: {len(bcf_data)}ê°œ ì´ìŠˆ")
    
    # GUID, Author, Keyword ì¶”ì¶œ
    guids = []
    authors = []
    keywords = []
    
    for issue in bcf_data:
        # GUID ì¶”ì¶œ
        if issue.get("topic_id"):
            guids.append(issue["topic_id"])
        
        # Author ì¶”ì¶œ
        if issue.get("author"):
            authors.append(issue["author"])
        
        # Keyword ì¶”ì¶œ (ì œëª©ê³¼ ì„¤ëª…ì—ì„œ)
        title = issue.get("title", "")
        description = issue.get("description", "")
        text = f"{title} {description}".lower()
        
        # ê±´ì„¤ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ
        construction_keywords = [
            "êµ¬ì¡°", "ì„¤ë¹„", "ì¶©ëŒ", "ë²½", "ë°”ë‹¥", "ì²œì¥", "ë¬¸", "ì°½ë¬¸", "ê³„ë‹¨", "ì—˜ë¦¬ë² ì´í„°",
            "ì „ê¸°", "ì¡°ëª…", "ë°°ê´€", "í™˜ê¸°", "ë‚œë°©", "ëƒ‰ë°©", "ì†Œë°©", "ë³´ì•ˆ", "í†µì‹ ", "ë„¤íŠ¸ì›Œí¬",
            "ì¬ë£Œ", "ì½˜í¬ë¦¬íŠ¸", "ì² ê·¼", "ê°•ì¬", "ëª©ì¬", "ìœ ë¦¬", "íƒ€ì¼", "í˜ì¸íŠ¸", "ë‹¨ì—´", "ë°©ìˆ˜",
            "ì„¤ê³„", "ë„ë©´", "ê³„íš", "ì¼ì •", "ì˜ˆì‚°", "í’ˆì§ˆ", "ì•ˆì „", "ê²€ì‚¬", "ìŠ¹ì¸", "ë³€ê²½"
        ]
        
        for keyword in construction_keywords:
            if keyword in text and keyword not in keywords:
                keywords.append(keyword)
    
    print(f"  ğŸ“Š ì¶”ì¶œëœ ë°ì´í„°:")
    print(f"    â€¢ GUID: {len(set(guids))}ê°œ")
    print(f"    â€¢ Author: {len(set(authors))}ê°œ")
    print(f"    â€¢ Keywords: {len(keywords)}ê°œ")
    
    return {
        "bcf_data": bcf_data,
        "guids": list(set(guids)),
        "authors": list(set(authors)),
        "keywords": keywords
    }


def generate_guid_queries(data, count=100):
    """GUID ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
    
    print(f"ğŸ” GUID ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘... ({count}ê°œ)")
    
    queries = []
    guids = data["guids"]
    
    # GUID ì¿¼ë¦¬ í…œí”Œë¦¿
    templates = [
        "GUID {guid}ì™€ ê´€ë ¨ëœ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "{guid}ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ì´ìŠˆ {guid}ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "{guid} ê´€ë ¨ ë¬¸ì œì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "GUID {guid}ì˜ í•´ê²° ìƒíƒœëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "{guid} ì´ìŠˆì˜ ìš°ì„ ìˆœìœ„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì´ìŠˆ {guid}ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì¸ê°€ìš”?",
        "{guid}ì™€ ì—°ê²°ëœ ë‹¤ë¥¸ ì´ìŠˆë“¤ì´ ìˆë‚˜ìš”?",
        "GUID {guid}ì˜ ìƒì„± ë‚ ì§œëŠ” ì–¸ì œì¸ê°€ìš”?",
        "{guid} ì´ìŠˆì˜ ë¶„ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    for i in range(count):
        guid = random.choice(guids)
        template = random.choice(templates)
        question = template.format(guid=guid)
        
        queries.append({
            "id": f"guid_{i+1:03d}",
            "question": question,
            "query_type": "guid",
            "expected_guid": guid,
            "difficulty": "easy"
        })
    
    print(f"  âœ… {len(queries)}ê°œ GUID ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    return queries


def generate_temporal_queries(data, count=100):
    """Temporal ì¿¼ë¦¬ ìƒì„±"""
    
    print(f"â° Temporal ì¿¼ë¦¬ ìƒì„± ì¤‘... ({count}ê°œ)")
    
    queries = []
    bcf_data = data["bcf_data"]
    
    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    dates = []
    for issue in bcf_data:
        if issue.get("created"):
            try:
                # ISO í˜•ì‹ ë‚ ì§œ íŒŒì‹±
                date_str = issue["created"]
                if date_str.endswith("Z"):
                    date_str = date_str.replace("Z", "+00:00")
                date = datetime.fromisoformat(date_str)
                # timezone ì •ë³´ ì œê±°í•˜ì—¬ naive datetimeìœ¼ë¡œ í†µì¼
                if date.tzinfo is not None:
                    date = date.replace(tzinfo=None)
                dates.append(date)
            except Exception as e:
                # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ì‹œ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ëŒ€ì²´
                dates.append(datetime.now())
                continue
    
    if dates:
        min_date = min(dates)
        max_date = max(dates)
    else:
        min_date = datetime.now() - timedelta(days=365)
        max_date = datetime.now()
    
    # Temporal ì¿¼ë¦¬ í…œí”Œë¦¿
    templates = [
        "ìµœê·¼ 1ì£¼ì¼ ë™ì•ˆ ìƒì„±ëœ ì´ìŠˆë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì§€ë‚œ ë‹¬ì— ë³´ê³ ëœ ë¬¸ì œì ë“¤ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "2024ë…„ì— ìƒì„±ëœ ëª¨ë“  ì´ìŠˆë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.",
        "ìµœê·¼ 3ê°œì›” ë™ì•ˆ í•´ê²°ë˜ì§€ ì•Šì€ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì˜¤ëŠ˜ ìƒì„±ëœ ìƒˆë¡œìš´ ì´ìŠˆê°€ ìˆë‚˜ìš”?",
        "ì§€ë‚œ ì£¼ì— ì—…ë°ì´íŠ¸ëœ ì´ìŠˆë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        "ìµœê·¼ 6ê°œì›” ë™ì•ˆì˜ ì´ìŠˆ íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.",
        "ì‘ë…„ ì´ë§˜ë•Œ ìƒì„±ëœ ì´ìŠˆì™€ ë¹„êµí•´ì£¼ì„¸ìš”.",
        "ë¶„ê¸°ë³„ ì´ìŠˆ ë°œìƒ í˜„í™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ìµœê·¼ 2ì£¼ì¼ ë™ì•ˆ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    for i in range(count):
        template = random.choice(templates)
        
        queries.append({
            "id": f"temporal_{i+1:03d}",
            "question": template,
            "query_type": "temporal",
            "time_range": "recent",
            "difficulty": "medium"
        })
    
    print(f"  âœ… {len(queries)}ê°œ Temporal ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    return queries


def generate_author_queries(data, count=100):
    """Author ì¿¼ë¦¬ ìƒì„±"""
    
    print(f"ğŸ‘¤ Author ì¿¼ë¦¬ ìƒì„± ì¤‘... ({count}ê°œ)")
    
    queries = []
    authors = data["authors"]
    
    # Author ì¿¼ë¦¬ í…œí”Œë¦¿
    templates = [
        "{author}ì´ ì‘ì„±í•œ ì´ìŠˆë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
        "{author}ê°€ ë‹´ë‹¹í•˜ê³  ìˆëŠ” ë¬¸ì œì ë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "{author}ì´ ë³´ê³ í•œ ìµœê·¼ ì´ìŠˆë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
        "{author}ê°€ í•´ê²°í•œ ì´ìŠˆë“¤ì˜ ëª©ë¡ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
        "{author}ì´ ìƒì„±í•œ ì´ìŠˆ ì¤‘ ì•„ì§ í•´ê²°ë˜ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "{author}ê°€ ë‹´ë‹¹í•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ì´ìŠˆ í˜„í™©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "{author}ì´ ì‘ì„±í•œ ì´ìŠˆ ì¤‘ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "{author}ê°€ ìµœê·¼ì— ì—…ë°ì´íŠ¸í•œ ì´ìŠˆë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.",
        "{author}ì´ ìƒì„±í•œ ì´ìŠˆë“¤ì˜ í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.",
        "{author}ê°€ ë‹´ë‹¹í•˜ëŠ” ì´ìŠˆ ì¤‘ ì§€ì—°ëœ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    for i in range(count):
        author = random.choice(authors) if authors else f"engineer_{i%10:03d}"
        template = random.choice(templates)
        question = template.format(author=author)
        
        queries.append({
            "id": f"author_{i+1:03d}",
            "question": question,
            "query_type": "author",
            "expected_author": author,
            "difficulty": "medium"
        })
    
    print(f"  âœ… {len(queries)}ê°œ Author ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    return queries


def generate_keyword_queries(data, count=100):
    """Keyword ì¿¼ë¦¬ ìƒì„±"""
    
    print(f"ğŸ”‘ Keyword ì¿¼ë¦¬ ìƒì„± ì¤‘... ({count}ê°œ)")
    
    queries = []
    keywords = data["keywords"]
    
    # Keyword ì¿¼ë¦¬ í…œí”Œë¦¿
    templates = [
        "{keyword} ê´€ë ¨ ì´ìŠˆë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        "{keyword} ë¬¸ì œì ì´ ìˆëŠ” ê³³ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "{keyword}ì™€ ê´€ë ¨ëœ ëª¨ë“  ì´ìŠˆë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.",
        "{keyword} ê´€ë ¨ í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "{keyword} ì´ìŠˆì˜ ìš°ì„ ìˆœìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "{keyword} ê´€ë ¨ ìµœê·¼ ì´ìŠˆë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
        "{keyword} ë¬¸ì œê°€ ë°œìƒí•œ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.",
        "{keyword} ê´€ë ¨ ì´ìŠˆì˜ í•´ê²° ë°©ë²•ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
        "{keyword}ì™€ ì—°ê´€ëœ ë‹¤ë¥¸ ë¬¸ì œì ë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "{keyword} ì´ìŠˆì˜ ë‹´ë‹¹ìë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
    ]
    
    for i in range(count):
        keyword = random.choice(keywords) if keywords else f"keyword_{i%20}"
        template = random.choice(templates)
        question = template.format(keyword=keyword)
        
        queries.append({
            "id": f"keyword_{i+1:03d}",
            "question": question,
            "query_type": "keyword",
            "expected_keyword": keyword,
            "difficulty": "medium"
        })
    
    print(f"  âœ… {len(queries)}ê°œ Keyword ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    return queries


def generate_complex_queries(data, count=100):
    """Complex ìì—°ì–´ ì¿¼ë¦¬ ìƒì„±"""
    
    print(f"ğŸ§  Complex ìì—°ì–´ ì¿¼ë¦¬ ìƒì„± ì¤‘... ({count}ê°œ)")
    
    queries = []
    
    # Complex ì¿¼ë¦¬ í…œí”Œë¦¿
    templates = [
        "ì‘ì—… ìš°ì„ ìˆœìœ„ë¥¼ ë†’ì—¬ì•¼ í•  êµ¬ì¡° ê´€ë ¨ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì§€ë‚œ ë‹¬ ìƒì„±ë˜ì—ˆì§€ë§Œ ì•„ì§ í•´ê²°ë˜ì§€ ì•Šì€ ì„¤ë¹„ ì¶©ëŒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "íŠ¹ì • ì¸µ(3ì¸µ)ê³¼ ê´€ë ¨ëœ ëª¨ë“  í˜‘ì—… ì´ìŠˆë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.",
        "ë™ì¼í•œ ì‘ì„±ìê°€ ë³´ê³ í•œ ìœ ì‚¬ ë¬¸ì œë“¤ì˜ íŒ¨í„´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ê¸´ê¸‰ë„ê°€ ë†’ì€ ì „ê¸° ê´€ë ¨ ì´ìŠˆ ì¤‘ í•´ê²°ì´ ì§€ì—°ëœ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì„¤ê³„ ë³€ê²½ìœ¼ë¡œ ì¸í•´ ë°œìƒí•œ ëª¨ë“  ì´ìŠˆë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.",
        "í’ˆì§ˆ ê²€ì‚¬ì—ì„œ ë°œê²¬ëœ ì£¼ìš” ë¬¸ì œì ë“¤ì„ ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.",
        "ì˜ˆì‚° ì´ˆê³¼ì™€ ê´€ë ¨ëœ ì´ìŠˆë“¤ì˜ ì›ì¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
        "ì•ˆì „ ì ê²€ì—ì„œ ë°œê²¬ëœ ìœ„í—˜ ìš”ì†Œë“¤ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.",
        "ì¼ì • ì§€ì—°ì„ ì•¼ê¸°í•˜ëŠ” ì£¼ìš” ì´ìŠˆë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        "ì„¤ë¹„ ì„¤ì¹˜ ê³¼ì •ì—ì„œ ë°œìƒí•œ ë¬¸ì œì ë“¤ì„ í•´ê²° ë°©ë²•ê³¼ í•¨ê»˜ ë³´ì—¬ì£¼ì„¸ìš”.",
        "êµ¬ì¡°ì  ê²°í•¨ê³¼ ê´€ë ¨ëœ ëª¨ë“  ì´ìŠˆì˜ ì‹¬ê°ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.",
        "í™˜ê²½ ì¹œí™”ì  ì¬ë£Œ ì‚¬ìš©ê³¼ ê´€ë ¨ëœ ì´ìŠˆë“¤ì„ ê²€í† í•´ì£¼ì„¸ìš”.",
        "ì ‘ê·¼ì„± ê°œì„ ì„ ìœ„í•œ ì´ìŠˆë“¤ì˜ êµ¬í˜„ í˜„í™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ì—ë„ˆì§€ íš¨ìœ¨ì„±ê³¼ ê´€ë ¨ëœ ë¬¸ì œì ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."
    ]
    
    for i in range(count):
        template = random.choice(templates)
        
        queries.append({
            "id": f"complex_{i+1:03d}",
            "question": template,
            "query_type": "complex",
            "difficulty": "hard",
            "requires_reasoning": True
        })
    
    print(f"  âœ… {len(queries)}ê°œ Complex ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    return queries


def generate_relationship_queries(data, count=100):
    """ê´€ê³„ íƒìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
    
    print(f"ğŸ”— ê´€ê³„ íƒìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘... ({count}ê°œ)")
    
    queries = []
    bcf_data = data["bcf_data"]
    
    # ê´€ê³„ íƒìƒ‰ ì¿¼ë¦¬ í…œí”Œë¦¿
    templates = [
        "ì´ìŠˆ {guid}ì™€ ê´€ë ¨ëœ ë‹¤ë¥¸ ì´ìŠˆë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "{guid} ì´ìŠˆì˜ ì›ì¸ê³¼ ê²°ê³¼ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.",
        "ì´ìŠˆ {guid}ì™€ ì—°ê´€ëœ ëª¨ë“  ë¬¸ì œì ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        "{guid} ì´ìŠˆê°€ ë‹¤ë¥¸ ì´ìŠˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
        "ì´ìŠˆ {guid}ì˜ ì˜ì¡´ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
        "{guid} ì´ìŠˆì™€ ìœ ì‚¬í•œ ë‹¤ë¥¸ ì´ìŠˆë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
        "ì´ìŠˆ {guid}ì˜ í•´ê²°ì´ ë‹¤ë¥¸ ì´ìŠˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "{guid} ì´ìŠˆì™€ ë™ì‹œì— ë°œìƒí•œ ë‹¤ë¥¸ ì´ìŠˆë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
        "ì´ìŠˆ {guid}ì˜ ì—°ì‡„ ë°˜ì‘ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
        "{guid} ì´ìŠˆì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹´ë‹¹ìë“¤ì˜ ì‘ì—…ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”."
    ]
    
    # GUID ì„ íƒì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    guids = [issue.get("topic_id") for issue in bcf_data if issue.get("topic_id")]
    
    for i in range(count):
        guid = random.choice(guids) if guids else f"guid_{i%50:03d}"
        template = random.choice(templates)
        question = template.format(guid=guid)
        
        queries.append({
            "id": f"relationship_{i+1:03d}",
            "question": question,
            "query_type": "relationship",
            "expected_guid": guid,
            "difficulty": "hard",
            "requires_graph_traversal": True
        })
    
    print(f"  âœ… {len(queries)}ê°œ ê´€ê³„ íƒìƒ‰ ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
    return queries


def create_comprehensive_gold_standard():
    """ì¢…í•© Gold Standard ìƒì„±"""
    
    print("ğŸš€ ì¢…í•© Gold Standard ìƒì„± ì‹œì‘")
    print("=" * 50)
    
    # 1. ë°ì´í„° ë¡œë“œ
    data = load_integrated_data()
    if not data:
        return
    
    print("\n" + "=" * 50)
    
    # 2. ê° ì¿¼ë¦¬ íƒ€ì…ë³„ ìƒì„±
    all_queries = []
    
    # GUID ì¿¼ë¦¬ (100ê°œ)
    guid_queries = generate_guid_queries(data, 100)
    all_queries.extend(guid_queries)
    
    print("\n" + "=" * 50)
    
    # Temporal ì¿¼ë¦¬ (100ê°œ)
    temporal_queries = generate_temporal_queries(data, 100)
    all_queries.extend(temporal_queries)
    
    print("\n" + "=" * 50)
    
    # Author ì¿¼ë¦¬ (100ê°œ)
    author_queries = generate_author_queries(data, 100)
    all_queries.extend(author_queries)
    
    print("\n" + "=" * 50)
    
    # Keyword ì¿¼ë¦¬ (100ê°œ)
    keyword_queries = generate_keyword_queries(data, 100)
    all_queries.extend(keyword_queries)
    
    print("\n" + "=" * 50)
    
    # Complex ì¿¼ë¦¬ (100ê°œ)
    complex_queries = generate_complex_queries(data, 100)
    all_queries.extend(complex_queries)
    
    print("\n" + "=" * 50)
    
    # Relationship ì¿¼ë¦¬ (100ê°œ)
    relationship_queries = generate_relationship_queries(data, 100)
    all_queries.extend(relationship_queries)
    
    print("\n" + "=" * 50)
    
    # 3. Gold Standard ì €ì¥
    output_file = Path("eval/gold_standard_comprehensive.jsonl")
    write_jsonl(str(output_file), all_queries)
    
    # 4. í†µê³„ ìƒì„±
    stats = {
        "total_queries": len(all_queries),
        "query_type_distribution": defaultdict(int),
        "difficulty_distribution": defaultdict(int),
        "generation_date": datetime.now().isoformat()
    }
    
    for query in all_queries:
        stats["query_type_distribution"][query["query_type"]] += 1
        stats["difficulty_distribution"][query["difficulty"]] += 1
    
    # í†µê³„ ì €ì¥
    stats_file = Path("eval/gold_standard_comprehensive_stats.json")
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(dict(stats), f, indent=2, ensure_ascii=False)
    
    print("ğŸ‰ ì¢…í•© Gold Standard ìƒì„± ì™„ë£Œ!")
    print(f"\nğŸ“Š ìƒì„± ê²°ê³¼:")
    print(f"  â€¢ ì´ ì§ˆì˜: {len(all_queries)}ê°œ")
    print(f"  â€¢ GUID: {stats['query_type_distribution']['guid']}ê°œ")
    print(f"  â€¢ Temporal: {stats['query_type_distribution']['temporal']}ê°œ")
    print(f"  â€¢ Author: {stats['query_type_distribution']['author']}ê°œ")
    print(f"  â€¢ Keyword: {stats['query_type_distribution']['keyword']}ê°œ")
    print(f"  â€¢ Complex: {stats['query_type_distribution']['complex']}ê°œ")
    print(f"  â€¢ Relationship: {stats['query_type_distribution']['relationship']}ê°œ")
    print(f"\nğŸ“ ì €ì¥ ìœ„ì¹˜:")
    print(f"  â€¢ Gold Standard: {output_file}")
    print(f"  â€¢ í†µê³„: {stats_file}")


if __name__ == "__main__":
    create_comprehensive_gold_standard()
