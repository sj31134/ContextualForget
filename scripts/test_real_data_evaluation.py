#!/usr/bin/env python3
"""
ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í‰ê°€ í…ŒìŠ¤íŠ¸
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from contextualforget.baselines.bm25_engine import BM25QueryEngine
from contextualforget.baselines.vector_engine import VectorQueryEngine
from contextualforget.query.contextual_forget_engine import ContextualForgetEngine
from contextualforget.query.adaptive_retrieval import HybridRetrievalEngine
from contextualforget.core.utils import read_jsonl
import pickle
import networkx as nx


def load_real_data_graph():
    """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê·¸ë˜í”„ ë¡œë“œ"""
    
    graph_file = Path("data/processed/real_graph/real_data_graph.pkl")
    if not graph_file.exists():
        raise FileNotFoundError(f"ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_file}")
    
    with open(graph_file, 'rb') as f:
        graph = pickle.load(f)
    
    print(f"âœ… ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ: {graph.number_of_nodes()}ê°œ ë…¸ë“œ, {graph.number_of_edges()}ê°œ ì—°ê²°")
    return graph


def initialize_engines_with_real_data():
    """ì‹¤ì œ ë°ì´í„°ë¡œ ì—”ì§„ë“¤ ì´ˆê¸°í™”"""
    
    print("ğŸ”§ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    
    # ê·¸ë˜í”„ ë¡œë“œ
    graph = load_real_data_graph()
    
    # ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¡° ìƒì„±
    graph_data = {
        'graph': graph,
        'nodes': list(graph.nodes(data=True))
    }
    
    engines = {}
    
    try:
        # BM25 ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” BM25 ì—”ì§„ ì´ˆê¸°í™”...")
        bm25_engine = BM25QueryEngine("BM25")
        bm25_engine.initialize(graph_data)
        engines['BM25'] = bm25_engine
        print("    âœ… BM25 ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ BM25 ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    try:
        # Vector ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” Vector ì—”ì§„ ì´ˆê¸°í™”...")
        vector_engine = VectorQueryEngine("Vector")
        vector_engine.initialize(graph_data)
        engines['Vector'] = vector_engine
        print("    âœ… Vector ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ Vector ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    try:
        # ContextualForget ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” ContextualForget ì—”ì§„ ì´ˆê¸°í™”...")
        cf_engine = ContextualForgetEngine(graph)
        engines['ContextualForget'] = cf_engine
        print("    âœ… ContextualForget ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ ContextualForget ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    try:
        # Hybrid ì—”ì§„ ì´ˆê¸°í™”
        print("  ğŸ” Hybrid ì—”ì§„ ì´ˆê¸°í™”...")
        if 'ContextualForget' in engines:
            # Hybrid ì—”ì§„ì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ base_enginesë¥¼ ê¸°ëŒ€í•¨
            base_engines = {
                'ContextualForget': engines['ContextualForget']
            }
            # BM25 ì—”ì§„ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if 'BM25' in engines:
                base_engines['BM25'] = engines['BM25']
            
            hybrid_engine = HybridRetrievalEngine(base_engines)
            engines['Hybrid'] = hybrid_engine
            print("    âœ… Hybrid ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"    âŒ Hybrid ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    print(f"âœ… ì´ {len(engines)}ê°œ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    return engines


def test_engines_with_real_gold_standard():
    """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ Gold Standardë¡œ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ Gold Standard í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. ì—”ì§„ ì´ˆê¸°í™”
    engines = initialize_engines_with_real_data()
    
    # 2. Gold Standard ë¡œë“œ
    gold_standard_file = Path("eval/gold_standard_real_data.jsonl")
    if not gold_standard_file.exists():
        print("âŒ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ Gold Standard íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    gold_standard = list(read_jsonl(str(gold_standard_file)))
    print(f"ğŸ“Š ë¡œë“œëœ Gold Standard ì§ˆë¬¸: {len(gold_standard)}ê°œ")
    
    # 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì²˜ìŒ 10ê°œë§Œ)
    test_questions = gold_standard[:10]
    print(f"ğŸ”¬ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìˆ˜: {len(test_questions)}ê°œ")
    
    results = {}
    
    for engine_name, engine in engines.items():
        print(f"\nğŸ” {engine_name} ì—”ì§„ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        engine_results = []
        start_time = time.time()
        
        for i, qa in enumerate(test_questions):
            try:
                question = qa['question']
                print(f"  ğŸ“ ì§ˆë¬¸ {i+1}: {question[:50]}...")
                
                # ì—”ì§„ë³„ ì¿¼ë¦¬ ì²˜ë¦¬
                if engine_name == 'ContextualForget':
                    result = engine.contextual_query(question)
                elif engine_name == 'Hybrid':
                    result = engine.query(question)
                else:
                    result = engine.process_query(question)
                
                # ê²°ê³¼ ë¶„ì„
                result_analysis = {
                    'question_id': i,
                    'question': question,
                    'gold_entities': qa.get('gold_entities', []),
                    'result': result,
                    'success': False,
                    'entities_found': len(result.get('entities', [])),
                    'confidence': result.get('confidence', 0.0)
                }
                
                # ì„±ê³µ ì—¬ë¶€ íŒë‹¨ (ê°„ë‹¨í•œ ê¸°ì¤€)
                if result.get('entities') and qa.get('gold_entities'):
                    retrieved_entities = set(result.get('entities', []))
                    gold_entities = set(qa.get('gold_entities', []))
                    overlap = len(retrieved_entities.intersection(gold_entities))
                    if overlap > 0:
                        result_analysis['success'] = True
                        result_analysis['overlap_count'] = overlap
                
                engine_results.append(result_analysis)
                
                print(f"    ğŸ“Š ê²°ê³¼: {result_analysis['entities_found']}ê°œ ì—”í‹°í‹°, ì‹ ë¢°ë„ {result_analysis['confidence']:.3f}, ì„±ê³µ: {result_analysis['success']}")
                
            except Exception as e:
                print(f"    âŒ ì˜¤ë¥˜: {e}")
                engine_results.append({
                    'question_id': i,
                    'question': question,
                    'error': str(e),
                    'success': False
                })
        
        end_time = time.time()
        
        # ì—”ì§„ë³„ í†µê³„ ê³„ì‚°
        successful_queries = sum(1 for r in engine_results if r.get('success', False))
        total_queries = len(engine_results)
        success_rate = successful_queries / total_queries if total_queries > 0 else 0
        
        avg_confidence = sum(r.get('confidence', 0) for r in engine_results) / total_queries if total_queries > 0 else 0
        avg_entities = sum(r.get('entities_found', 0) for r in engine_results) / total_queries if total_queries > 0 else 0
        
        results[engine_name] = {
            'total_queries': total_queries,
            'successful_queries': successful_queries,
            'success_rate': success_rate,
            'avg_confidence': avg_confidence,
            'avg_entities_found': avg_entities,
            'execution_time': end_time - start_time,
            'detailed_results': engine_results
        }
        
        print(f"  ğŸ“ˆ {engine_name} ê²°ê³¼:")
        print(f"    ì„±ê³µë¥ : {success_rate:.1%}")
        print(f"    í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"    í‰ê·  ì—”í‹°í‹° ìˆ˜: {avg_entities:.1f}")
        print(f"    ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    
    # 4. ê²°ê³¼ ì €ì¥
    results_file = Path("data/analysis/real_data_test_results.json")
    results_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {results_file}")
    
    # 5. ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    for engine_name, stats in results.items():
        print(f"\nğŸ” {engine_name}:")
        print(f"  ì„±ê³µë¥ : {stats['success_rate']:.1%}")
        print(f"  í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}")
        print(f"  í‰ê·  ì—”í‹°í‹° ìˆ˜: {stats['avg_entities_found']:.1f}")
        print(f"  ì‹¤í–‰ ì‹œê°„: {stats['execution_time']:.2f}ì´ˆ")
    
    return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í‰ê°€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    try:
        results = test_engines_with_real_gold_standard()
        
        print("\n" + "="*60)
        print("ğŸ‰ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í‰ê°€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
        # ì£¼ìš” ê°œì„ ì‚¬í•­ í™•ì¸
        print("\nğŸ“ˆ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        for engine_name, stats in results.items():
            if stats['success_rate'] > 0:
                print(f"  âœ… {engine_name}: {stats['success_rate']:.1%} ì„±ê³µë¥  ë‹¬ì„±!")
            else:
                print(f"  âš ï¸ {engine_name}: ì—¬ì „íˆ 0% ì„±ê³µë¥ ")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
